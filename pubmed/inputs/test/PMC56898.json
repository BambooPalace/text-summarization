{"id": "PMC56898", "inputs": [{"text": "access to automated dna sequencing technology has made possible the rapid generation and analysis of gene transcripts expressed in organisms via expressed sequence tags ( ests ) .", "tokens": ["access", "to", "automated", "dna", "sequencing", "technology", "has", "made", "possible", "the", "rapid", "generation", "and", "analysis", "of", "gene", "transcripts", "expressed", "in", "organisms", "via", "expressed", "sequence", "tags", "(", "ests", ")", "."], "sentence_id": 1, "word_count": 28}, {"text": "this information has helped to identify those genes expressed in particular stages of development and in specialized tissues or organs .", "tokens": ["this", "information", "has", "helped", "to", "identify", "those", "genes", "expressed", "in", "particular", "stages", "of", "development", "and", "in", "specialized", "tissues", "or", "organs", "."], "sentence_id": 2, "word_count": 21}, {"text": "novel gene products and target leads for therapeutic intervention can also be gleaned rapidly from ests . a more detailed understanding of the molecular interactions between symbionts , whether pathogenic or mutualistic , is also possible with this approach . for a sequence isolated from interacting symbionts , determining its cellular role ( or roles )", "tokens": ["novel", "gene", "products", "and", "target", "leads", "for", "therapeutic", "intervention", "can", "also", "be", "gleaned", "rapidly", "from", "ests", ".", "a", "more", "detailed", "understanding", "of", "the", "molecular", "interactions", "between", "symbionts", ",", "whether", "pathogenic", "or", "mutualistic", ",", "is", "also", "possible", "with", "this", "approach", ".", "for", "a", "sequence", "isolated", "from", "interacting", "symbionts", ",", "determining", "its", "cellular", "role", "(", "or", "roles", ")"], "sentence_id": 3, "word_count": 56}, {"text": "we refer to this challenge as ' the problem ' : given a sequence x expressed in an interaction between species a and b , did x originate from a or b ?", "tokens": ["we", "refer", "to", "this", "challenge", "as", "'", "the", "problem", "'", ":", "given", "a", "sequence", "x", "expressed", "in", "an", "interaction", "between", "species", "a", "and", "b", ",", "did", "x", "originate", "from", "a", "or", "b", "?"], "sentence_id": 4, "word_count": 33}, {"text": "various solutions are readily conceived , each with merits and faults . here , we show that a comparative lexical analysis of word counts ( specifically , hexamer frequencies ) , previously used to detect library contamination in sequencing projects , provides a powerful computational basis to infer a transcript 's species of origin . experimentally , one can attempt to solve the problem by hybridizing a clone ( as probe ) to genomic dna ( target ) from both species and determining to which target the probe hybridizes .", "tokens": ["various", "solutions", "are", "readily", "conceived", ",", "each", "with", "merits", "and", "faults", ".", "here", ",", "we", "show", "that", "a", "comparative", "lexical", "analysis", "of", "word", "counts", "(", "specifically", ",", "hexamer", "frequencies", ")", ",", "previously", "used", "to", "detect", "library", "contamination", "in", "sequencing", "projects", ",", "provides", "a", "powerful", "computational", "basis", "to", "infer", "a", "transcript", "'s", "species", "of", "origin", ".", "experimentally", ",", "one", "can", "attempt", "to", "solve", "the", "problem", "by", "hybridizing", "a", "clone", "(", "as", "probe", ")", "to", "genomic", "dna", "(", "target", ")", "from", "both", "species", "and", "determining", "to", "which", "target", "the", "probe", "hybridizes", "."], "sentence_id": 5, "word_count": 90}, {"text": "however , if a sequence is highly conserved in the two taxa , hybridization stringency conditions can influence the outcome considerably . for high - throughput est sequence analysis ,", "tokens": ["however", ",", "if", "a", "sequence", "is", "highly", "conserved", "in", "the", "two", "taxa", ",", "hybridization", "stringency", "conditions", "can", "influence", "the", "outcome", "considerably", ".", "for", "high", "-", "throughput", "est", "sequence", "analysis", ","], "sentence_id": 6, "word_count": 30}, {"text": "source verification by hybridization is impractical in terms of time and reagents . as an alternative to in vitro hybridization , several computational solutions are possible .", "tokens": ["source", "verification", "by", "hybridization", "is", "impractical", "in", "terms", "of", "time", "and", "reagents", ".", "as", "an", "alternative", "to", "in", "vitro", "hybridization", ",", "several", "computational", "solutions", "are", "possible", "."], "sentence_id": 7, "word_count": 27}, {"text": "were the genome sequence of both species completely determined , one could simply use sequence similarity searching . however , most plant hosts and their microbial symbionts have little or no genomic sequence data available , which makes this approach very unreliable .", "tokens": ["were", "the", "genome", "sequence", "of", "both", "species", "completely", "determined", ",", "one", "could", "simply", "use", "sequence", "similarity", "searching", ".", "however", ",", "most", "plant", "hosts", "and", "their", "microbial", "symbionts", "have", "little", "or", "no", "genomic", "sequence", "data", "available", ",", "which", "makes", "this", "approach", "very", "unreliable", "."], "sentence_id": 8, "word_count": 43}, {"text": "strong similarity to a sequence from one organism does not preclude the possibility that a similar sequence is present in the other species .", "tokens": ["strong", "similarity", "to", "a", "sequence", "from", "one", "organism", "does", "not", "preclude", "the", "possibility", "that", "a", "similar", "sequence", "is", "present", "in", "the", "other", "species", "."], "sentence_id": 9, "word_count": 24}, {"text": "exploiting this fact may seem a viable solution to the problem , as it has proven suitable for predicting the presence of introns among exons in genomic dna .", "tokens": ["exploiting", "this", "fact", "may", "seem", "a", "viable", "solution", "to", "the", "problem", ",", "as", "it", "has", "proven", "suitable", "for", "predicting", "the", "presence", "of", "introns", "among", "exons", "in", "genomic", "dna", "."], "sentence_id": 10, "word_count": 29}, {"text": "however , it really is not practical , because of the need to know the reading frame for translation of a messenger rna into an amino acid .", "tokens": ["however", ",", "it", "really", "is", "not", "practical", ",", "because", "of", "the", "need", "to", "know", "the", "reading", "frame", "for", "translation", "of", "a", "messenger", "rna", "into", "an", "amino", "acid", "."], "sentence_id": 11, "word_count": 28}, {"text": "est data are of notoriously unreliable quality , sometimes having a large proportion of ambiguous bases , and sometimes having single base - pair insertions or deletions , which disrupt a reading frame .", "tokens": ["est", "data", "are", "of", "notoriously", "unreliable", "quality", ",", "sometimes", "having", "a", "large", "proportion", "of", "ambiguous", "bases", ",", "and", "sometimes", "having", "single", "base", "-", "pair", "insertions", "or", "deletions", ",", "which", "disrupt", "a", "reading", "frame", "."], "sentence_id": 12, "word_count": 34}, {"text": "word counting is less prone to these sources of error , and uses information intrinsic to biases in codon usage by counting codon pairs as hexamers in a sliding window , whereas codons are read in non - overlapping , tiled windows .", "tokens": ["word", "counting", "is", "less", "prone", "to", "these", "sources", "of", "error", ",", "and", "uses", "information", "intrinsic", "to", "biases", "in", "codon", "usage", "by", "counting", "codon", "pairs", "as", "hexamers", "in", "a", "sliding", "window", ",", "whereas", "codons", "are", "read", "in", "non", "-", "overlapping", ",", "tiled", "windows", "."], "sentence_id": 13, "word_count": 43}, {"text": "an intuitive approach to the problem that examines sequence composition is to compare the guanine and cytosine ( gc ) base content of a sequence with other sequences from the species being studied .", "tokens": ["an", "intuitive", "approach", "to", "the", "problem", "that", "examines", "sequence", "composition", "is", "to", "compare", "the", "guanine", "and", "cytosine", "(", "gc", ")", "base", "content", "of", "a", "sequence", "with", "other", "sequences", "from", "the", "species", "being", "studied", "."], "sentence_id": 14, "word_count": 34}, {"text": "when two species ' genomes have different gc content , this method can be very useful .", "tokens": ["when", "two", "species", "'", "genomes", "have", "different", "gc", "content", ",", "this", "method", "can", "be", "very", "useful", "."], "sentence_id": 15, "word_count": 17}, {"text": "in a recent investigation , for instance , sequences from the stramenopile plant pathogen phytophthora sojae and its soybean ( glycine max ) host showed a 20% difference in mean gc content . the origin of a number of sequences could readily be identified this way , but a large proportion could not , because of considerable overlap in the distributions ' tails .", "tokens": ["in", "a", "recent", "investigation", ",", "for", "instance", ",", "sequences", "from", "the", "stramenopile", "plant", "pathogen", "phytophthora", "sojae", "and", "its", "soybean", "(", "glycine", "max", ")", "host", "showed", "a", "20%", "difference", "in", "mean", "gc", "content", ".", "the", "origin", "of", "a", "number", "of", "sequences", "could", "readily", "be", "identified", "this", "way", ",", "but", "a", "large", "proportion", "could", "not", ",", "because", "of", "considerable", "overlap", "in", "the", "distributions", "'", "tails", "."], "sentence_id": 16, "word_count": 64}, {"text": "counting frequencies of gc is simple word counting , where the word size k is 1/2 : only two semi - words , g / c and a / t are counted .", "tokens": ["counting", "frequencies", "of", "gc", "is", "simple", "word", "counting", ",", "where", "the", "word", "size", "k", "is", "1/2", ":", "only", "two", "semi", "-", "words", ",", "g", "/", "c", "and", "a", "/", "t", "are", "counted", "."], "sentence_id": 17, "word_count": 33}, {"text": "an alternative approach to determining the origin of a sequence is suggested by previous work on analysis of word counts , or k - tuple frequencies , which was intended as a means of evaluating a library for contamination when sequencing from a single model organism .", "tokens": ["an", "alternative", "approach", "to", "determining", "the", "origin", "of", "a", "sequence", "is", "suggested", "by", "previous", "work", "on", "analysis", "of", "word", "counts", ",", "or", "k", "-", "tuple", "frequencies", ",", "which", "was", "intended", "as", "a", "means", "of", "evaluating", "a", "library", "for", "contamination", "when", "sequencing", "from", "a", "single", "model", "organism", "."], "sentence_id": 18, "word_count": 47}, {"text": "the word - counting method provides distinct advantages over other computational methods . unlike sequence - similarity searching", "tokens": ["the", "word", "-", "counting", "method", "provides", "distinct", "advantages", "over", "other", "computational", "methods", ".", "unlike", "sequence", "-", "similarity", "searching"], "sentence_id": 19, "word_count": 18}, {"text": ", it does not require that the full protein - coding content of both genomes be known for reasonable inferences to be made .", "tokens": [",", "it", "does", "not", "require", "that", "the", "full", "protein", "-", "coding", "content", "of", "both", "genomes", "be", "known", "for", "reasonable", "inferences", "to", "be", "made", "."], "sentence_id": 20, "word_count": 24}, {"text": "further , word counting is sensitive to biases in codon usage and gc content commonly observed when comparing taxa , but does not require knowledge of the reading frame for amino - acid translation .", "tokens": ["further", ",", "word", "counting", "is", "sensitive", "to", "biases", "in", "codon", "usage", "and", "gc", "content", "commonly", "observed", "when", "comparing", "taxa", ",", "but", "does", "not", "require", "knowledge", "of", "the", "reading", "frame", "for", "amino", "-", "acid", "translation", "."], "sentence_id": 21, "word_count": 35}, {"text": "that is , the underlying differences between the two organisms that result in base composition or codon usage biases can also be detected by counting words .", "tokens": ["that", "is", ",", "the", "underlying", "differences", "between", "the", "two", "organisms", "that", "result", "in", "base", "composition", "or", "codon", "usage", "biases", "can", "also", "be", "detected", "by", "counting", "words", "."], "sentence_id": 22, "word_count": 27}, {"text": "unlike gc analysis , lexical analysis establishes a clear threshold above or below which we can infer the species of origin , and a confidence level for an inference can readily be assigned .", "tokens": ["unlike", "gc", "analysis", ",", "lexical", "analysis", "establishes", "a", "clear", "threshold", "above", "or", "below", "which", "we", "can", "infer", "the", "species", "of", "origin", ",", "and", "a", "confidence", "level", "for", "an", "inference", "can", "readily", "be", "assigned", "."], "sentence_id": 23, "word_count": 34}, {"text": "dunning 's likelihood - ratio test of word dissimilarities   also has the appealing property of being non - parametric , having no assumption of normality for the underlying frequency distribution , which makes it statistically powerful . dunning   demonstrated that unreliable results can be obtained from parametric tests , such as  , particularly in such cases as lexical analysis . in the experiments detailed below , we first validate the word - counting method on sequences whose", "tokens": ["dunning", "'s", "likelihood", "-", "ratio", "test", "of", "word", "dissimilarities", "also", "has", "the", "appealing", "property", "of", "being", "non", "-", "parametric", ",", "having", "no", "assumption", "of", "normality", "for", "the", "underlying", "frequency", "distribution", ",", "which", "makes", "it", "statistically", "powerful", ".", "dunning", "demonstrated", "that", "unreliable", "results", "can", "be", "obtained", "from", "parametric", "tests", ",", "such", "as", ",", "particularly", "in", "such", "cases", "as", "lexical", "analysis", ".", "in", "the", "experiments", "detailed", "below", ",", "we", "first", "validate", "the", "word", "-", "counting", "method", "on", "sequences", "whose"], "sentence_id": 24, "word_count": 77}, {"text": "origin and function are known , then compare it with ability to diagnose the origin of sequences with distributions of gc content .", "tokens": ["origin", "and", "function", "are", "known", ",", "then", "compare", "it", "with", "ability", "to", "diagnose", "the", "origin", "of", "sequences", "with", "distributions", "of", "gc", "content", "."], "sentence_id": 25, "word_count": 23}, {"text": "we examine sequences from pathogenic interactions between species from the genus phytophthora and the plant hosts g. max and medicago truncatula , then apply the word - counting approach to sequences from two microbial mutualists in association with m. truncatula , the arbuscular mycorrhizal zygomycete glomus versiforme , and the nitrogen - fixing bacterium sinorhizobium meliloti .", "tokens": ["we", "examine", "sequences", "from", "pathogenic", "interactions", "between", "species", "from", "the", "genus", "phytophthora", "and", "the", "plant", "hosts", "g.", "max", "and", "medicago", "truncatula", ",", "then", "apply", "the", "word", "-", "counting", "approach", "to", "sequences", "from", "two", "microbial", "mutualists", "in", "association", "with", "m.", "truncatula", ",", "the", "arbuscular", "mycorrhizal", "zygomycete", "glomus", "versiforme", ",", "and", "the", "nitrogen", "-", "fixing", "bacterium", "sinorhizobium", "meliloti", "."], "sentence_id": 26, "word_count": 57}, {"text": "validation sequence accession numbers , gene names , and comparison results appear in table 1 .", "tokens": ["validation", "sequence", "accession", "numbers", ",", "gene", "names", ",", "and", "comparison", "results", "appear", "in", "table", "1", "."], "sentence_id": 27, "word_count": 16}, {"text": "the word - counting method was generally quite reliable when tested against sequences of known origin , being wrong in 3 cases out of 50 ; a phosphate transporter from g. versiforme and two in planta - induced genes from phytophthora infestans were misidentified as plant sequences .", "tokens": ["the", "word", "-", "counting", "method", "was", "generally", "quite", "reliable", "when", "tested", "against", "sequences", "of", "known", "origin", ",", "being", "wrong", "in", "3", "cases", "out", "of", "50", ";", "a", "phosphate", "transporter", "from", "g.", "versiforme", "and", "two", "in", "planta", "-", "induced", "genes", "from", "phytophthora", "infestans", "were", "misidentified", "as", "plant", "sequences", "."], "sentence_id": 28, "word_count": 48}, {"text": "this indicates a failure rate of 6% - all false negatives under the null hypothesis that a transcript originates from the plant host .", "tokens": ["this", "indicates", "a", "failure", "rate", "of", "6%", "-", "all", "false", "negatives", "under", "the", "null", "hypothesis", "that", "a", "transcript", "originates", "from", "the", "plant", "host", "."], "sentence_id": 29, "word_count": 24}, {"text": "performance of the method was not influenced by whether the isolated source of a sequence was an mrna or dna molecule , as indicated by the column labeled ' mrna ? ' .", "tokens": ["performance", "of", "the", "method", "was", "not", "influenced", "by", "whether", "the", "isolated", "source", "of", "a", "sequence", "was", "an", "mrna", "or", "dna", "molecule", ",", "as", "indicated", "by", "the", "column", "labeled", "'", "mrna", "?", "'", "."], "sentence_id": 30, "word_count": 33}, {"text": "distributions of gc content are approximately normal in two of three cases studied , those of axenic p. sojae cultures ( figure 1 ) . for sequences from infected plant cultures ,", "tokens": ["distributions", "of", "gc", "content", "are", "approximately", "normal", "in", "two", "of", "three", "cases", "studied", ",", "those", "of", "axenic", "p.", "sojae", "cultures", "(", "figure", "1", ")", ".", "for", "sequences", "from", "infected", "plant", "cultures", ","], "sentence_id": 31, "word_count": 32}, {"text": "roughly 25% of a total of 927 infected g. max sequences contain less than 50% gc ; most of these are likely to be plant transcripts .", "tokens": ["roughly", "25%", "of", "a", "total", "of", "927", "infected", "g.", "max", "sequences", "contain", "less", "than", "50%", "gc", ";", "most", "of", "these", "are", "likely", "to", "be", "plant", "transcripts", "."], "sentence_id": 32, "word_count": 27}, {"text": "this is a considerably greater number than for axenic p. sojae cultures , in which fewer than 5% of mycelia and zoospore isolates contain less than 50% gc .", "tokens": ["this", "is", "a", "considerably", "greater", "number", "than", "for", "axenic", "p.", "sojae", "cultures", ",", "in", "which", "fewer", "than", "5%", "of", "mycelia", "and", "zoospore", "isolates", "contain", "less", "than", "50%", "gc", "."], "sentence_id": 33, "word_count": 29}, {"text": "several properties of cumulative distribution functions warrant comment , to help explain similar plots from word dissimilarity comparisons ( figures 1b,2a ) .", "tokens": ["several", "properties", "of", "cumulative", "distribution", "functions", "warrant", "comment", ",", "to", "help", "explain", "similar", "plots", "from", "word", "dissimilarity", "comparisons", "(", "figures", "1b,2a", ")", "."], "sentence_id": 34, "word_count": 23}, {"text": "the median of a distribution occurs where the function reaches a cumulative probability of 0.5 .", "tokens": ["the", "median", "of", "a", "distribution", "occurs", "where", "the", "function", "reaches", "a", "cumulative", "probability", "of", "0.5", "."], "sentence_id": 35, "word_count": 16}, {"text": "medians from all three p. sojae libraries are similar , varying by less than 4% gc ( figure 1b ) .", "tokens": ["medians", "from", "all", "three", "p.", "sojae", "libraries", "are", "similar", ",", "varying", "by", "less", "than", "4%", "gc", "(", "figure", "1b", ")", "."], "sentence_id": 36, "word_count": 21}, {"text": "other moments of the distributions are readily apparent ; the variance is inversely related to the slope at the median value of the function", "tokens": ["other", "moments", "of", "the", "distributions", "are", "readily", "apparent", ";", "the", "variance", "is", "inversely", "related", "to", "the", "slope", "at", "the", "median", "value", "of", "the", "function"], "sentence_id": 37, "word_count": 24}, {"text": ". a useful property of cumulative distribution functions is that any point on the y axis gives the integrated area ( cumulative probability ) under the curve .", "tokens": [".", "a", "useful", "property", "of", "cumulative", "distribution", "functions", "is", "that", "any", "point", "on", "the", "y", "axis", "gives", "the", "integrated", "area", "(", "cumulative", "probability", ")", "under", "the", "curve", "."], "sentence_id": 38, "word_count": 28}, {"text": "we use this property to establish experiment - wide false - positive and false - negative rates ( figure 2a ) . in this case ,", "tokens": ["we", "use", "this", "property", "to", "establish", "experiment", "-", "wide", "false", "-", "positive", "and", "false", "-", "negative", "rates", "(", "figure", "2a", ")", ".", "in", "this", "case", ","], "sentence_id": 39, "word_count": 26}, {"text": "calibration curves from hexamer dissimilarity tests , shown in figure 2b as solid black lines for plant and dashed black lines for stramenopile training sequences are approximately normal .", "tokens": ["calibration", "curves", "from", "hexamer", "dissimilarity", "tests", ",", "shown", "in", "figure", "2b", "as", "solid", "black", "lines", "for", "plant", "and", "dashed", "black", "lines", "for", "stramenopile", "training", "sequences", "are", "approximately", "normal", "."], "sentence_id": 40, "word_count": 29}, {"text": "the medians differ considerably , with only about 10% percent overlap in the two distributions ' tails about the neutral t - value of zero . superimposed", "tokens": ["the", "medians", "differ", "considerably", ",", "with", "only", "about", "10%", "percent", "overlap", "in", "the", "two", "distributions", "'", "tails", "about", "the", "neutral", "t", "-", "value", "of", "zero", ".", "superimposed"], "sentence_id": 41, "word_count": 27}, {"text": "are comparison curves from p. sojae test sets ( figure 2b ) , which parallel the gc content curves in figure 1b but show slightly less variance .", "tokens": ["are", "comparison", "curves", "from", "p.", "sojae", "test", "sets", "(", "figure", "2b", ")", ",", "which", "parallel", "the", "gc", "content", "curves", "in", "figure", "1b", "but", "show", "slightly", "less", "variance", "."], "sentence_id": 42, "word_count": 28}, {"text": "axenic sequences are clearly more like stramenopiles ( b1 ) than plants ( a1 ) in hexamer composition , with all but a small percentage having positive t values .", "tokens": ["axenic", "sequences", "are", "clearly", "more", "like", "stramenopiles", "(", "b1", ")", "than", "plants", "(", "a1", ")", "in", "hexamer", "composition", ",", "with", "all", "but", "a", "small", "percentage", "having", "positive", "t", "values", "."], "sentence_id": 43, "word_count": 30}, {"text": "plant - like sequences are as abundant in the mixed library as detected by gc content , about 23% . as expected , the two methods agree , having positively correlated values for gc and t ( r = 0.852 , p < 10 , v = 2,641 ) . looking in more detail at the paired dissimilarity values ( figure 3 ) ,", "tokens": ["plant", "-", "like", "sequences", "are", "as", "abundant", "in", "the", "mixed", "library", "as", "detected", "by", "gc", "content", ",", "about", "23%", ".", "as", "expected", ",", "the", "two", "methods", "agree", ",", "having", "positively", "correlated", "values", "for", "gc", "and", "t", "(", "r", "=", "0.852", ",", "p", "<", "10", ",", "v", "=", "2,641", ")", ".", "looking", "in", "more", "detail", "at", "the", "paired", "dissimilarity", "values", "(", "figure", "3", ")", ","], "sentence_id": 44, "word_count": 64}, {"text": "the magnitudes of dissimilarity are also apparent , with longer sequences having larger dissimilarity values .", "tokens": ["the", "magnitudes", "of", "dissimilarity", "are", "also", "apparent", ",", "with", "longer", "sequences", "having", "larger", "dissimilarity", "values", "."], "sentence_id": 45, "word_count": 16}, {"text": "blastx similarity searches against the protein sequences in nr , a non - redundant library of proteins   revealed that none of the 12 plant - like mycelial transcripts significantly resemble known proteins ( e > 10 ) . among the top ten most plant - like transcripts from the infected g. max library", "tokens": ["blastx", "similarity", "searches", "against", "the", "protein", "sequences", "in", "nr", ",", "a", "non", "-", "redundant", "library", "of", "proteins", "revealed", "that", "none", "of", "the", "12", "plant", "-", "like", "mycelial", "transcripts", "significantly", "resemble", "known", "proteins", "(", "e", ">", "10", ")", ".", "among", "the", "top", "ten", "most", "plant", "-", "like", "transcripts", "from", "the", "infected", "g.", "max", "library"], "sentence_id": 46, "word_count": 53}, {"text": ", three had no significant matches , four matched putative arabidopsis thaliana proteins , and three matched known g. max proteins : cytochrome p450 ( accession af022460 , e < 10 ) , methylglyoxalase ( accession p46417 , e < 10 ) , and a ripening related protein ( accession af127110 , e < 10 ) .", "tokens": [",", "three", "had", "no", "significant", "matches", ",", "four", "matched", "putative", "arabidopsis", "thaliana", "proteins", ",", "and", "three", "matched", "known", "g.", "max", "proteins", ":", "cytochrome", "p450", "(", "accession", "af022460", ",", "e", "<", "10", ")", ",", "methylglyoxalase", "(", "accession", "p46417", ",", "e", "<", "10", ")", ",", "and", "a", "ripening", "related", "protein", "(", "accession", "af127110", ",", "e", "<", "10", ")", "."], "sentence_id": 47, "word_count": 57}, {"text": "thus , the majority of the most plant - like transcripts in the infected soybean library strongly resemble characterized plant sequences .", "tokens": ["thus", ",", "the", "majority", "of", "the", "most", "plant", "-", "like", "transcripts", "in", "the", "infected", "soybean", "library", "strongly", "resemble", "characterized", "plant", "sequences", "."], "sentence_id": 48, "word_count": 22}, {"text": "analysis results from all p. sojae and mixed - culture transcripts are available as additional data files , grouped by the library from which transcripts were sequenced .", "tokens": ["analysis", "results", "from", "all", "p.", "sojae", "and", "mixed", "-", "culture", "transcripts", "are", "available", "as", "additional", "data", "files", ",", "grouped", "by", "the", "library", "from", "which", "transcripts", "were", "sequenced", "."], "sentence_id": 49, "word_count": 28}, {"text": "figure 4 shows that calibration curves from comparing plant and microbial symbiont training sets have good separation and minimal overlap ( about 10% ) in two of three cases , but not for training set b2 , comprised of zygomycetes and chytridiomycetes , which overlaps considerably with plants ( figure 4b ) .", "tokens": ["figure", "4", "shows", "that", "calibration", "curves", "from", "comparing", "plant", "and", "microbial", "symbiont", "training", "sets", "have", "good", "separation", "and", "minimal", "overlap", "(", "about", "10%", ")", "in", "two", "of", "three", "cases", ",", "but", "not", "for", "training", "set", "b2", ",", "comprised", "of", "zygomycetes", "and", "chytridiomycetes", ",", "which", "overlaps", "considerably", "with", "plants", "(", "figure", "4b", ")", "."], "sentence_id": 50, "word_count": 53}, {"text": "when comparing between plants and bacteria , the error rates are  = 0.052 and  = 0.084 , much lower than when comparing plants ( a2 , medicago ) with fungi ( b2 , zygomycetes and chytridiomycetes ) .", "tokens": ["when", "comparing", "between", "plants", "and", "bacteria", ",", "the", "error", "rates", "are", "=", "0.052", "and", "=", "0.084", ",", "much", "lower", "than", "when", "comparing", "plants", "(", "a2", ",", "medicago", ")", "with", "fungi", "(", "b2", ",", "zygomycetes", "and", "chytridiomycetes", ")", "."], "sentence_id": 51, "word_count": 38}, {"text": "error rates for comparing stramenopiles and p. infestans ests with plants are as in figure 2 (  = 0.088 ,  = 0.032 ) . also shown in figure 4", "tokens": ["error", "rates", "for", "comparing", "stramenopiles", "and", "p.", "infestans", "ests", "with", "plants", "are", "as", "in", "figure", "2", "(", "=", "0.088", ",", "=", "0.032", ")", ".", "also", "shown", "in", "figure", "4"], "sentence_id": 52, "word_count": 29}, {"text": "all resemble calibration curves from plant sequences , having similar medians and slightly less variance than the plant calibration curves .", "tokens": ["all", "resemble", "calibration", "curves", "from", "plant", "sequences", ",", "having", "similar", "medians", "and", "slightly", "less", "variance", "than", "the", "plant", "calibration", "curves", "."], "sentence_id": 53, "word_count": 21}, {"text": "comparison curves show that the great majority of test sequences are more plant - like than otherwise , with 20% or less resembling microbial symbionts more closely than plants", "tokens": ["comparison", "curves", "show", "that", "the", "great", "majority", "of", "test", "sequences", "are", "more", "plant", "-", "like", "than", "otherwise", ",", "with", "20%", "or", "less", "resembling", "microbial", "symbionts", "more", "closely", "than", "plants"], "sentence_id": 54, "word_count": 29}, {"text": ". a greater proportion of microbial sequences is present in the m. truncatula - g .", "tokens": [".", "a", "greater", "proportion", "of", "microbial", "sequences", "is", "present", "in", "the", "m.", "truncatula", "-", "g", "."], "sentence_id": 55, "word_count": 16}, {"text": "versiforme interaction library ( 20% , figure 4b ) than in the p. medicaginis - infected m. truncatula library ( 5% , figure 4a ) .", "tokens": ["versiforme", "interaction", "library", "(", "20%", ",", "figure", "4b", ")", "than", "in", "the", "p.", "medicaginis", "-", "infected", "m.", "truncatula", "library", "(", "5%", ",", "figure", "4a", ")", "."], "sentence_id": 56, "word_count": 26}, {"text": "however , long 's root - hair enriched library ( mtrhe )   had a greater proportion of putative microbial sequences present ( 7% and 25% ) than any of the libraries isolated from symbiont - associated cultures .", "tokens": ["however", ",", "long", "'s", "root", "-", "hair", "enriched", "library", "(", "mtrhe", ")", "had", "a", "greater", "proportion", "of", "putative", "microbial", "sequences", "present", "(", "7%", "and", "25%", ")", "than", "any", "of", "the", "libraries", "isolated", "from", "symbiont", "-", "associated", "cultures", "."], "sentence_id": 57, "word_count": 38}, {"text": "the axenic and nodulating root libraries had the smallest portion of putative microbial transcripts ( < 2% , figure 4c ) , with the axenic library closely resembling nodulating root libraries .", "tokens": ["the", "axenic", "and", "nodulating", "root", "libraries", "had", "the", "smallest", "portion", "of", "putative", "microbial", "transcripts", "(", "<", "2%", ",", "figure", "4c", ")", ",", "with", "the", "axenic", "library", "closely", "resembling", "nodulating", "root", "libraries", "."], "sentence_id": 58, "word_count": 32}, {"text": "the method of preparing a library can affect the proportion of plant and non - plant sequences , as discussed below .", "tokens": ["the", "method", "of", "preparing", "a", "library", "can", "affect", "the", "proportion", "of", "plant", "and", "non", "-", "plant", "sequences", ",", "as", "discussed", "below", "."], "sentence_id": 59, "word_count": 22}, {"text": "paired dissimilarity values in figure 5 show in greater detail which sequences are more or less like plant and symbiont .", "tokens": ["paired", "dissimilarity", "values", "in", "figure", "5", "show", "in", "greater", "detail", "which", "sequences", "are", "more", "or", "less", "like", "plant", "and", "symbiont", "."], "sentence_id": 60, "word_count": 21}, {"text": "considerable variation in the degree of dissimilarity to both training sets is clear , largely due to variation in the length of sequences within test sets .", "tokens": ["considerable", "variation", "in", "the", "degree", "of", "dissimilarity", "to", "both", "training", "sets", "is", "clear", ",", "largely", "due", "to", "variation", "in", "the", "length", "of", "sequences", "within", "test", "sets", "."], "sentence_id": 61, "word_count": 27}, {"text": "d(b ) in figure 4 , most sequences lie above the identity function , and resemble the plant host more closely than the microbial symbiont .", "tokens": ["d(b", ")", "in", "figure", "4", ",", "most", "sequences", "lie", "above", "the", "identity", "function", ",", "and", "resemble", "the", "plant", "host", "more", "closely", "than", "the", "microbial", "symbiont", "."], "sentence_id": 62, "word_count": 26}, {"text": "mycorrhizal test sequences are more difficult to differentiate than sequences from the rhizobacterial or pathogenic associations , as seen by the diminished variation about the identity function in mycorrhizal comparisons ( figure 5b ) , contrasted with comparisons from pathogen - infected and nodulating root libraries ( figures 5a and c , respectively ) .", "tokens": ["mycorrhizal", "test", "sequences", "are", "more", "difficult", "to", "differentiate", "than", "sequences", "from", "the", "rhizobacterial", "or", "pathogenic", "associations", ",", "as", "seen", "by", "the", "diminished", "variation", "about", "the", "identity", "function", "in", "mycorrhizal", "comparisons", "(", "figure", "5b", ")", ",", "contrasted", "with", "comparisons", "from", "pathogen", "-", "infected", "and", "nodulating", "root", "libraries", "(", "figures", "5a", "and", "c", ",", "respectively", ")", "."], "sentence_id": 63, "word_count": 55}, {"text": "analysis results from all m. truncatula and mixed - culture transcripts are available as additional data files , grouped by the library from which transcripts were sequenced , and sorted from the least plant - like transcripts to the most plant - like .", "tokens": ["analysis", "results", "from", "all", "m.", "truncatula", "and", "mixed", "-", "culture", "transcripts", "are", "available", "as", "additional", "data", "files", ",", "grouped", "by", "the", "library", "from", "which", "transcripts", "were", "sequenced", ",", "and", "sorted", "from", "the", "least", "plant", "-", "like", "transcripts", "to", "the", "most", "plant", "-", "like", "."], "sentence_id": 64, "word_count": 44}, {"text": "clearly , the word - counting approach provides a reliable solution to the problem of source identification with known confidence , and has several significant advantages .", "tokens": ["clearly", ",", "the", "word", "-", "counting", "approach", "provides", "a", "reliable", "solution", "to", "the", "problem", "of", "source", "identification", "with", "known", "confidence", ",", "and", "has", "several", "significant", "advantages", "."], "sentence_id": 65, "word_count": 27}, {"text": "the reliability of the method is best justified in terms of the favorable validation test results , and is further corroborated by agreement with an analysis of gc content . in test cases", "tokens": ["the", "reliability", "of", "the", "method", "is", "best", "justified", "in", "terms", "of", "the", "favorable", "validation", "test", "results", ",", "and", "is", "further", "corroborated", "by", "agreement", "with", "an", "analysis", "of", "gc", "content", ".", "in", "test", "cases"], "sentence_id": 66, "word_count": 33}, {"text": "where the correct answer is known a priori , results were correct within error rates expected from overlap in training sets .", "tokens": ["where", "the", "correct", "answer", "is", "known", "a", "priori", ",", "results", "were", "correct", "within", "error", "rates", "expected", "from", "overlap", "in", "training", "sets", "."], "sentence_id": 67, "word_count": 22}, {"text": "( recall that  = 0.088 for comparisons between plants and stramenopiles , and  = 0.052 for comparisons between plants and bacteria . ) unlike gc content , the problem is clearly resolved by word counting with a threshold value of t = 0 , and with statistical rigor , because false - positive and false - negative rates for a set of comparisons are readily computed from cumulative distributions of dissimilarity between two training sets .", "tokens": ["(", "recall", "that", "=", "0.088", "for", "comparisons", "between", "plants", "and", "stramenopiles", ",", "and", "=", "0.052", "for", "comparisons", "between", "plants", "and", "bacteria", ".", ")", "unlike", "gc", "content", ",", "the", "problem", "is", "clearly", "resolved", "by", "word", "counting", "with", "a", "threshold", "value", "of", "t", "=", "0", ",", "and", "with", "statistical", "rigor", ",", "because", "false", "-", "positive", "and", "false", "-", "negative", "rates", "for", "a", "set", "of", "comparisons", "are", "readily", "computed", "from", "cumulative", "distributions", "of", "dissimilarity", "between", "two", "training", "sets", "."], "sentence_id": 68, "word_count": 76}, {"text": "optimal statistical power ( minimal false - negative rate ) is ensured when using a likelihood - ratio test statistic , as demonstrated by the pearson - neyman theorem .", "tokens": ["optimal", "statistical", "power", "(", "minimal", "false", "-", "negative", "rate", ")", "is", "ensured", "when", "using", "a", "likelihood", "-", "ratio", "test", "statistic", ",", "as", "demonstrated", "by", "the", "pearson", "-", "neyman", "theorem", "."], "sentence_id": 69, "word_count": 30}, {"text": "rather , it is sufficient that the training set be related to , but not necessarily congeners of , the species from which sequences are being compared .", "tokens": ["rather", ",", "it", "is", "sufficient", "that", "the", "training", "set", "be", "related", "to", ",", "but", "not", "necessarily", "congeners", "of", ",", "the", "species", "from", "which", "sequences", "are", "being", "compared", "."], "sentence_id": 70, "word_count": 28}, {"text": "sequences from several species of the genus phytophthora were correctly distinguished from plant and bacterial sequences , and three genes from agrobacterium tumefaciens were correctly identified as representing a bacterial sequence .", "tokens": ["sequences", "from", "several", "species", "of", "the", "genus", "phytophthora", "were", "correctly", "distinguished", "from", "plant", "and", "bacterial", "sequences", ",", "and", "three", "genes", "from", "agrobacterium", "tumefaciens", "were", "correctly", "identified", "as", "representing", "a", "bacterial", "sequence", "."], "sentence_id": 71, "word_count": 32}, {"text": "however , several caveats warrant prudence . transcribed sequences that do not encode proteins , but rather catalytic single - stranded rnas such as transfer and ribosomal rnas , should be treated independently because they are more highly conserved across taxa than messenger rnas . also , filtering or trimming of low - complexity repeat regions , such as poly(a ) or poly(t ) tracts , is helpful because comparison results can be influenced by the abundance of a single hexamer .", "tokens": ["however", ",", "several", "caveats", "warrant", "prudence", ".", "transcribed", "sequences", "that", "do", "not", "encode", "proteins", ",", "but", "rather", "catalytic", "single", "-", "stranded", "rnas", "such", "as", "transfer", "and", "ribosomal", "rnas", ",", "should", "be", "treated", "independently", "because", "they", "are", "more", "highly", "conserved", "across", "taxa", "than", "messenger", "rnas", ".", "also", ",", "filtering", "or", "trimming", "of", "low", "-", "complexity", "repeat", "regions", ",", "such", "as", "poly(a", ")", "or", "poly(t", ")", "tracts", ",", "is", "helpful", "because", "comparison", "results", "can", "be", "influenced", "by", "the", "abundance", "of", "a", "single", "hexamer", "."], "sentence_id": 72, "word_count": 82}, {"text": "early in our investigations , using one set of training sequences obtained from directionally cloned p.", "tokens": ["early", "in", "our", "investigations", ",", "using", "one", "set", "of", "training", "sequences", "obtained", "from", "directionally", "cloned", "p."], "sentence_id": 73, "word_count": 16}, {"text": "it eventually became clear that , as the p. infestans sequences were all single - pass reads from the 5 ' end of a clone generated with the t3 primer , few sequences complementary to the 3 ' end of the mrna sequence were present in the training set .", "tokens": ["it", "eventually", "became", "clear", "that", ",", "as", "the", "p.", "infestans", "sequences", "were", "all", "single", "-", "pass", "reads", "from", "the", "5", "'", "end", "of", "a", "clone", "generated", "with", "the", "t3", "primer", ",", "few", "sequences", "complementary", "to", "the", "3", "'", "end", "of", "the", "mrna", "sequence", "were", "present", "in", "the", "training", "set", "."], "sentence_id": 74, "word_count": 50}, {"text": "large amounts of the poly(t ) hexamer would be expected when sequencing reverse complements of mrnas obtained from 3 ' sequences generated with the t7 primer .", "tokens": ["large", "amounts", "of", "the", "poly(t", ")", "hexamer", "would", "be", "expected", "when", "sequencing", "reverse", "complements", "of", "mrnas", "obtained", "from", "3", "'", "sequences", "generated", "with", "the", "t7", "primer", "."], "sentence_id": 75, "word_count": 27}, {"text": "as a result , any sequence that contained a poly(t ) tract tended to resemble the plant sequences .", "tokens": ["as", "a", "result", ",", "any", "sequence", "that", "contained", "a", "poly(t", ")", "tract", "tended", "to", "resemble", "the", "plant", "sequences", "."], "sentence_id": 76, "word_count": 19}, {"text": "further , because the error rates for an inference depend on the degree to which calibration curves overlap , the best results are obtained where overlap is minimal . despite these caveats , word counting presents a viable solution to the problem .", "tokens": ["further", ",", "because", "the", "error", "rates", "for", "an", "inference", "depend", "on", "the", "degree", "to", "which", "calibration", "curves", "overlap", ",", "the", "best", "results", "are", "obtained", "where", "overlap", "is", "minimal", ".", "despite", "these", "caveats", ",", "word", "counting", "presents", "a", "viable", "solution", "to", "the", "problem", "."], "sentence_id": 77, "word_count": 43}, {"text": "the p. sojae - infected g. max library provides a clear example of contrast in both hexamer composition and gc content , resulting in readily diagnosed origins .", "tokens": ["the", "p.", "sojae", "-", "infected", "g.", "max", "library", "provides", "a", "clear", "example", "of", "contrast", "in", "both", "hexamer", "composition", "and", "gc", "content", ",", "resulting", "in", "readily", "diagnosed", "origins", "."], "sentence_id": 78, "word_count": 28}, {"text": "for clear separation between the two species to appear , the two must differ in composition and a detectable proportion of transcripts from each species must be present in the library . to be detectable , the proportion of transcripts present from a particular species must be greater than the error rate obtained from calibration curves . though these criteria are true for the infected g. max library ( t < 0 for < 25% of 927 transcripts ) , they do not appear to be true for the m. truncatula libraries we analyzed ( t < 0 for 8099% of 8903,017 transcripts ) . in the p. medicaginis interaction library", "tokens": ["for", "clear", "separation", "between", "the", "two", "species", "to", "appear", ",", "the", "two", "must", "differ", "in", "composition", "and", "a", "detectable", "proportion", "of", "transcripts", "from", "each", "species", "must", "be", "present", "in", "the", "library", ".", "to", "be", "detectable", ",", "the", "proportion", "of", "transcripts", "present", "from", "a", "particular", "species", "must", "be", "greater", "than", "the", "error", "rate", "obtained", "from", "calibration", "curves", ".", "though", "these", "criteria", "are", "true", "for", "the", "infected", "g.", "max", "library", "(", "t", "<", "0", "for", "<", "25%", "of", "927", "transcripts", ")", ",", "they", "do", "not", "appear", "to", "be", "true", "for", "the", "m.", "truncatula", "libraries", "we", "analyzed", "(", "t", "<", "0", "for", "8099%", "of", "8903,017", "transcripts", ")", ".", "in", "the", "p.", "medicaginis", "interaction", "library"], "sentence_id": 79, "word_count": 111}, {"text": "the p. sojae - infected library was prepared two days after infection , using a susceptible plant host strain , so as to maximize the number of pathogen transcripts present in the host tissue .", "tokens": ["the", "p.", "sojae", "-", "infected", "library", "was", "prepared", "two", "days", "after", "infection", ",", "using", "a", "susceptible", "plant", "host", "strain", ",", "so", "as", "to", "maximize", "the", "number", "of", "pathogen", "transcripts", "present", "in", "the", "host", "tissue", "."], "sentence_id": 80, "word_count": 35}, {"text": "medicaginis - infected library was prepared ten days after infection and individual plants varied in their degree of susceptibility ( c. vance , unpublished data ) .", "tokens": ["medicaginis", "-", "infected", "library", "was", "prepared", "ten", "days", "after", "infection", "and", "individual", "plants", "varied", "in", "their", "degree", "of", "susceptibility", "(", "c.", "vance", ",", "unpublished", "data", ")", "."], "sentence_id": 81, "word_count": 27}, {"text": "plants were also inoculated in a different manner : ground mycelia were dissolved in sterile water and incubated , and the resulting inoculum was pipetted onto the soil surface , rather than the plant .", "tokens": ["plants", "were", "also", "inoculated", "in", "a", "different", "manner", ":", "ground", "mycelia", "were", "dissolved", "in", "sterile", "water", "and", "incubated", ",", "and", "the", "resulting", "inoculum", "was", "pipetted", "onto", "the", "soil", "surface", ",", "rather", "than", "the", "plant", "."], "sentence_id": 82, "word_count": 35}, {"text": "these differences in how tissues were cultured prior to library preparation could have produced the disparate abundance of plant transcripts , though both libraries were prepared from plant tissues infected with phytophthora . for mycorrhizal root libraries", "tokens": ["these", "differences", "in", "how", "tissues", "were", "cultured", "prior", "to", "library", "preparation", "could", "have", "produced", "the", "disparate", "abundance", "of", "plant", "transcripts", ",", "though", "both", "libraries", "were", "prepared", "from", "plant", "tissues", "infected", "with", "phytophthora", ".", "for", "mycorrhizal", "root", "libraries"], "sentence_id": 83, "word_count": 37}, {"text": ", we might explain the relative lack of symbiont sequences as resulting simply from a relative lack of transcripts in the host tissue .", "tokens": [",", "we", "might", "explain", "the", "relative", "lack", "of", "symbiont", "sequences", "as", "resulting", "simply", "from", "a", "relative", "lack", "of", "transcripts", "in", "the", "host", "tissue", "."], "sentence_id": 84, "word_count": 24}, {"text": "we might therefore expect that most of the transcripts therein originate from the plant host . confounding this result ,", "tokens": ["we", "might", "therefore", "expect", "that", "most", "of", "the", "transcripts", "therein", "originate", "from", "the", "plant", "host", ".", "confounding", "this", "result", ","], "sentence_id": 85, "word_count": 20}, {"text": "the error rates in this comparison are the greatest among all the comparisons we performed , most likely because the evolutionary distance between fungi ( zygomycetes and chytridiomycetes ) and plants is the least among comparisons . also , zygomycete protein - coding sequences are rare in genbank , which resulted in a small training set for these fungi , and may have amplified any biases .", "tokens": ["the", "error", "rates", "in", "this", "comparison", "are", "the", "greatest", "among", "all", "the", "comparisons", "we", "performed", ",", "most", "likely", "because", "the", "evolutionary", "distance", "between", "fungi", "(", "zygomycetes", "and", "chytridiomycetes", ")", "and", "plants", "is", "the", "least", "among", "comparisons", ".", "also", ",", "zygomycete", "protein", "-", "coding", "sequences", "are", "rare", "in", "genbank", ",", "which", "resulted", "in", "a", "small", "training", "set", "for", "these", "fungi", ",", "and", "may", "have", "amplified", "any", "biases", "."], "sentence_id": 86, "word_count": 67}, {"text": "the high false - negative rate probably led to a failure to detect some symbiont transcripts . in nodulating root libraries", "tokens": ["the", "high", "false", "-", "negative", "rate", "probably", "led", "to", "a", "failure", "to", "detect", "some", "symbiont", "transcripts", ".", "in", "nodulating", "root", "libraries"], "sentence_id": 87, "word_count": 21}, {"text": ", we do not expect to observe an abundance of bacterial transcripts , because bacteria generally do not form polyadenylated mrnas . as the protocols used to extract and purify mrnas from tissue lysate for the libraries cited in this study all relied on the presence of polyadenylation sites", "tokens": [",", "we", "do", "not", "expect", "to", "observe", "an", "abundance", "of", "bacterial", "transcripts", ",", "because", "bacteria", "generally", "do", "not", "form", "polyadenylated", "mrnas", ".", "as", "the", "protocols", "used", "to", "extract", "and", "purify", "mrnas", "from", "tissue", "lysate", "for", "the", "libraries", "cited", "in", "this", "study", "all", "relied", "on", "the", "presence", "of", "polyadenylation", "sites"], "sentence_id": 88, "word_count": 49}, {"text": "the abundance of putative microbial symbiont transcripts among sequences from a pure plant root library is difficult to interpret .", "tokens": ["the", "abundance", "of", "putative", "microbial", "symbiont", "transcripts", "among", "sequences", "from", "a", "pure", "plant", "root", "library", "is", "difficult", "to", "interpret", "."], "sentence_id": 89, "word_count": 20}, {"text": "the predicted portion of microbial transcripts was greater in the axenic root - hair enriched library than in mixed cultures .", "tokens": ["the", "predicted", "portion", "of", "microbial", "transcripts", "was", "greater", "in", "the", "axenic", "root", "-", "hair", "enriched", "library", "than", "in", "mixed", "cultures", "."], "sentence_id": 90, "word_count": 21}, {"text": "error rates were greatest for comparisons between training sets from plant and pooled zygomycete and chytridiomycete sequences .", "tokens": ["error", "rates", "were", "greatest", "for", "comparisons", "between", "training", "sets", "from", "plant", "and", "pooled", "zygomycete", "and", "chytridiomycete", "sequences", "."], "sentence_id": 91, "word_count": 18}, {"text": "the 13% false - positive rate does not completely explain why about 15% of root - hair enriched transcripts resemble fungal hexamer composition more closely than plants , and warrants further study .", "tokens": ["the", "13%", "false", "-", "positive", "rate", "does", "not", "completely", "explain", "why", "about", "15%", "of", "root", "-", "hair", "enriched", "transcripts", "resemble", "fungal", "hexamer", "composition", "more", "closely", "than", "plants", ",", "and", "warrants", "further", "study", "."], "sentence_id": 92, "word_count": 33}, {"text": "care had been taken to avoid contaminating plant tissue cultures by culturing seedlings in covered plates .", "tokens": ["care", "had", "been", "taken", "to", "avoid", "contaminating", "plant", "tissue", "cultures", "by", "culturing", "seedlings", "in", "covered", "plates", "."], "sentence_id": 93, "word_count": 17}, {"text": "because of concern that ethylene accumulation in covered plates could improperly stimulate nodulation - related gene expression , seedlings were treated with ag2so4 , an inhibitor of the plants ' response to ethylene .", "tokens": ["because", "of", "concern", "that", "ethylene", "accumulation", "in", "covered", "plates", "could", "improperly", "stimulate", "nodulation", "-", "related", "gene", "expression", ",", "seedlings", "were", "treated", "with", "ag2so4", ",", "an", "inhibitor", "of", "the", "plants", "'", "response", "to", "ethylene", "."], "sentence_id": 94, "word_count": 34}, {"text": "inhibition of the ethylene response could have resulted in synthesis of transcripts that are uncharacteristic of plant roots .", "tokens": ["inhibition", "of", "the", "ethylene", "response", "could", "have", "resulted", "in", "synthesis", "of", "transcripts", "that", "are", "uncharacteristic", "of", "plant", "roots", "."], "sentence_id": 95, "word_count": 19}, {"text": "analysis of another axenic root - hair enriched library , particularly one provided a carbon source to identify potential contaminants , and not treated with an inhibitor of ethylene response , would be an informative test .", "tokens": ["analysis", "of", "another", "axenic", "root", "-", "hair", "enriched", "library", ",", "particularly", "one", "provided", "a", "carbon", "source", "to", "identify", "potential", "contaminants", ",", "and", "not", "treated", "with", "an", "inhibitor", "of", "ethylene", "response", ",", "would", "be", "an", "informative", "test", "."], "sentence_id": 96, "word_count": 37}, {"text": "the transcripts identified as most and least like plant or symbiont might also be studied in more detail as candidate participants in symbiosis .", "tokens": ["the", "transcripts", "identified", "as", "most", "and", "least", "like", "plant", "or", "symbiont", "might", "also", "be", "studied", "in", "more", "detail", "as", "candidate", "participants", "in", "symbiosis", "."], "sentence_id": 97, "word_count": 24}, {"text": "symbiotic interactions , whether pathogenic or mutualistic , present novel challenges to both plant hosts and the biologists who study them . computational approaches , in concert with experimental verification , can help resolve these challenges .", "tokens": ["symbiotic", "interactions", ",", "whether", "pathogenic", "or", "mutualistic", ",", "present", "novel", "challenges", "to", "both", "plant", "hosts", "and", "the", "biologists", "who", "study", "them", ".", "computational", "approaches", ",", "in", "concert", "with", "experimental", "verification", ",", "can", "help", "resolve", "these", "challenges", "."], "sentence_id": 98, "word_count": 37}, {"text": "to characterize hexamer frequencies in plant hosts and their microbial symbionts , we collected sets of training sequences from public databases and edited them for quality .", "tokens": ["to", "characterize", "hexamer", "frequencies", "in", "plant", "hosts", "and", "their", "microbial", "symbionts", ",", "we", "collected", "sets", "of", "training", "sequences", "from", "public", "databases", "and", "edited", "them", "for", "quality", "."], "sentence_id": 99, "word_count": 27}, {"text": "training sets were chosen to be representative of , but obtained independently from , taxa participating in symbiotic associations for which a diagnosis of origin would be made . because the species being compared are represented unevenly in public sequence databases , taxa were chosen so that roughly the same number of genes were analyzed in each training set , rather than simply to maximize the numbers of species or sequences present .", "tokens": ["training", "sets", "were", "chosen", "to", "be", "representative", "of", ",", "but", "obtained", "independently", "from", ",", "taxa", "participating", "in", "symbiotic", "associations", "for", "which", "a", "diagnosis", "of", "origin", "would", "be", "made", ".", "because", "the", "species", "being", "compared", "are", "represented", "unevenly", "in", "public", "sequence", "databases", ",", "taxa", "were", "chosen", "so", "that", "roughly", "the", "same", "number", "of", "genes", "were", "analyzed", "in", "each", "training", "set", ",", "rather", "than", "simply", "to", "maximize", "the", "numbers", "of", "species", "or", "sequences", "present", "."], "sentence_id": 100, "word_count": 73}, {"text": "training sets represent protein - coding sequences from three taxonomic groupings : plants ( a1 , medicago and glycine spp . ) , either fungi ( b2 , zygomycetes and chytridiomycetes ) or stramenopiles ( b1 ) , including ests from p. infestans , and bacteria ( b3 , rhizobium , sinorhizobium and bradyrhizobium ) .", "tokens": ["training", "sets", "represent", "protein", "-", "coding", "sequences", "from", "three", "taxonomic", "groupings", ":", "plants", "(", "a1", ",", "medicago", "and", "glycine", "spp", ".", ")", ",", "either", "fungi", "(", "b2", ",", "zygomycetes", "and", "chytridiomycetes", ")", "or", "stramenopiles", "(", "b1", ")", ",", "including", "ests", "from", "p.", "infestans", ",", "and", "bacteria", "(", "b3", ",", "rhizobium", ",", "sinorhizobium", "and", "bradyrhizobium", ")", "."], "sentence_id": 101, "word_count": 56}, {"text": "we performed pairwise comparisons with two different , taxon - specific training sets ( a and b ) to infer the origin of a transcript .", "tokens": ["we", "performed", "pairwise", "comparisons", "with", "two", "different", ",", "taxon", "-", "specific", "training", "sets", "(", "a", "and", "b", ")", "to", "infer", "the", "origin", "of", "a", "transcript", "."], "sentence_id": 102, "word_count": 26}, {"text": "training sets were obtained by querying the genbank database using the entrez retrieval tool . a preliminary query by taxon name obtained all available nucleotide sequences from that taxon , then the limits option excluded ests , stss ( sequence - tagged sites ) , gsss ( genome survey sequences ) , working draft sequences , and patented sequences from the query set . organellar ( mitochondrial and chloroplast ) dna was also excluded via the limits option .", "tokens": ["training", "sets", "were", "obtained", "by", "querying", "the", "genbank", "database", "using", "the", "entrez", "retrieval", "tool", ".", "a", "preliminary", "query", "by", "taxon", "name", "obtained", "all", "available", "nucleotide", "sequences", "from", "that", "taxon", ",", "then", "the", "limits", "option", "excluded", "ests", ",", "stss", "(", "sequence", "-", "tagged", "sites", ")", ",", "gsss", "(", "genome", "survey", "sequences", ")", ",", "working", "draft", "sequences", ",", "and", "patented", "sequences", "from", "the", "query", "set", ".", "organellar", "(", "mitochondrial", "and", "chloroplast", ")", "dna", "was", "also", "excluded", "via", "the", "limits", "option", "."], "sentence_id": 103, "word_count": 79}, {"text": "a query term to require that a sequence contain a protein - coding region ( cds ) was also added , which excluded ribosomal and transfer rna sequences .", "tokens": ["a", "query", "term", "to", "require", "that", "a", "sequence", "contain", "a", "protein", "-", "coding", "region", "(", "cds", ")", "was", "also", "added", ",", "which", "excluded", "ribosomal", "and", "transfer", "rna", "sequences", "."], "sentence_id": 104, "word_count": 29}, {"text": "the results consisted of all sequences that contain a nuclear protein - coding sequence available for that taxon at the time of the query .", "tokens": ["the", "results", "consisted", "of", "all", "sequences", "that", "contain", "a", "nuclear", "protein", "-", "coding", "sequence", "available", "for", "that", "taxon", "at", "the", "time", "of", "the", "query", "."], "sentence_id": 105, "word_count": 25}, {"text": "( changing slightly the composition of training sets between those dates did not notably affect the experimental outcome . ) following a previously established protocol , we used a resampling procedure to evaluate the degree of overlap between distributions of hexamer composition obtained from comparing two training sets . in this protocol", "tokens": ["(", "changing", "slightly", "the", "composition", "of", "training", "sets", "between", "those", "dates", "did", "not", "notably", "affect", "the", "experimental", "outcome", ".", ")", "following", "a", "previously", "established", "protocol", ",", "we", "used", "a", "resampling", "procedure", "to", "evaluate", "the", "degree", "of", "overlap", "between", "distributions", "of", "hexamer", "composition", "obtained", "from", "comparing", "two", "training", "sets", ".", "in", "this", "protocol"], "sentence_id": 106, "word_count": 52}, {"text": ", we resampled each training set 40 times by random partitioning into training ( for hexamer counts ) and test calculation pools . to control for any bias introduced by length variation ,", "tokens": [",", "we", "resampled", "each", "training", "set", "40", "times", "by", "random", "partitioning", "into", "training", "(", "for", "hexamer", "counts", ")", "and", "test", "calculation", "pools", ".", "to", "control", "for", "any", "bias", "introduced", "by", "length", "variation", ","], "sentence_id": 107, "word_count": 33}, {"text": "a program randomly clipped 300 nucleotide fragments for word counting . as a result , one random 300 nucleotide fragment from each training sequence was present in the training set during a single resampling replicate ; independent replicates contained different , randomly chosen training sequences and 300 nucleotide fragments .", "tokens": ["a", "program", "randomly", "clipped", "300", "nucleotide", "fragments", "for", "word", "counting", ".", "as", "a", "result", ",", "one", "random", "300", "nucleotide", "fragment", "from", "each", "training", "sequence", "was", "present", "in", "the", "training", "set", "during", "a", "single", "resampling", "replicate", ";", "independent", "replicates", "contained", "different", ",", "randomly", "chosen", "training", "sequences", "and", "300", "nucleotide", "fragments", "."], "sentence_id": 108, "word_count": 50}, {"text": "values of the test statistic from 40 resampled replicates were pooled for calibration purposes . as with the original protocol , we pooled the resulting test statistic distributions , normalized them as cumulative distributions , and then evaluated them for overlap .", "tokens": ["values", "of", "the", "test", "statistic", "from", "40", "resampled", "replicates", "were", "pooled", "for", "calibration", "purposes", ".", "as", "with", "the", "original", "protocol", ",", "we", "pooled", "the", "resulting", "test", "statistic", "distributions", ",", "normalized", "them", "as", "cumulative", "distributions", ",", "and", "then", "evaluated", "them", "for", "overlap", "."], "sentence_id": 109, "word_count": 42}, {"text": "we call the resulting comparisons ' calibration curves ' , as they are not used directly to make inferences , but rather indirectly , to evaluate the degree of separation in hexamer counts from different taxa", "tokens": ["we", "call", "the", "resulting", "comparisons", "'", "calibration", "curves", "'", ",", "as", "they", "are", "not", "used", "directly", "to", "make", "inferences", ",", "but", "rather", "indirectly", ",", "to", "evaluate", "the", "degree", "of", "separation", "in", "hexamer", "counts", "from", "different", "taxa"], "sentence_id": 110, "word_count": 36}, {"text": ". overlap of calibration curves should be minimal to yield the most statistically powerful results possible .", "tokens": [".", "overlap", "of", "calibration", "curves", "should", "be", "minimal", "to", "yield", "the", "most", "statistically", "powerful", "results", "possible", "."], "sentence_id": 111, "word_count": 17}, {"text": "due to considerable overlap of calibration curves between taxonomically general , inclusive training sets ( that is , all eudicots , all fungi and miscellaneous eukaryotes , and all eubacteria , data not shown ) , we opted to work with specific training sets that included only the most species - specific sequences available , while maintaining approximately equal sample sizes across taxa .", "tokens": ["due", "to", "considerable", "overlap", "of", "calibration", "curves", "between", "taxonomically", "general", ",", "inclusive", "training", "sets", "(", "that", "is", ",", "all", "eudicots", ",", "all", "fungi", "and", "miscellaneous", "eukaryotes", ",", "and", "all", "eubacteria", ",", "data", "not", "shown", ")", ",", "we", "opted", "to", "work", "with", "specific", "training", "sets", "that", "included", "only", "the", "most", "species", "-", "specific", "sequences", "available", ",", "while", "maintaining", "approximately", "equal", "sample", "sizes", "across", "taxa", "."], "sentence_id": 112, "word_count": 64}, {"text": "the most challenging case was that of the arbuscular mycorrhizal fungi , for which very few protein - coding sequences are available . to increase the amount of data in this training set ( b2 ) without biasing sample sizes , we pooled sequences from all species in the zygomycetes with all available chytridiomycete coding sequences , and compared this training set with a set from a single plant genus , medicago ( a2 ) .", "tokens": ["the", "most", "challenging", "case", "was", "that", "of", "the", "arbuscular", "mycorrhizal", "fungi", ",", "for", "which", "very", "few", "protein", "-", "coding", "sequences", "are", "available", ".", "to", "increase", "the", "amount", "of", "data", "in", "this", "training", "set", "(", "b2", ")", "without", "biasing", "sample", "sizes", ",", "we", "pooled", "sequences", "from", "all", "species", "in", "the", "zygomycetes", "with", "all", "available", "chytridiomycete", "coding", "sequences", ",", "and", "compared", "this", "training", "set", "with", "a", "set", "from", "a", "single", "plant", "genus", ",", "medicago", "(", "a2", ")", "."], "sentence_id": 113, "word_count": 76}, {"text": "we chose this option , rather than including an arbitrary subset of sequences from the ascomycetes and basidiomycetes , because zygomycetes and chytridiomycetes have diverged from their common ancestor less recently than the ascomycetes and basidiomycetes , based on 18s ribosomal rna sequence data .", "tokens": ["we", "chose", "this", "option", ",", "rather", "than", "including", "an", "arbitrary", "subset", "of", "sequences", "from", "the", "ascomycetes", "and", "basidiomycetes", ",", "because", "zygomycetes", "and", "chytridiomycetes", "have", "diverged", "from", "their", "common", "ancestor", "less", "recently", "than", "the", "ascomycetes", "and", "basidiomycetes", ",", "based", "on", "18s", "ribosomal", "rna", "sequence", "data", "."], "sentence_id": 114, "word_count": 45}, {"text": "that is , the ascomycetes and basidiomycetes are more highly derived from the common fungal ancestor than zygomycetes and chytridiomycetes , which resemble more closely the ancestral state in modern lineages . starting with a full set of sequences , we filtered for high - quality sequences by trimming regions having extensive ambiguous bases ( n - rich ) and poly(a ) or poly(t ) regions .", "tokens": ["that", "is", ",", "the", "ascomycetes", "and", "basidiomycetes", "are", "more", "highly", "derived", "from", "the", "common", "fungal", "ancestor", "than", "zygomycetes", "and", "chytridiomycetes", ",", "which", "resemble", "more", "closely", "the", "ancestral", "state", "in", "modern", "lineages", ".", "starting", "with", "a", "full", "set", "of", "sequences", ",", "we", "filtered", "for", "high", "-", "quality", "sequences", "by", "trimming", "regions", "having", "extensive", "ambiguous", "bases", "(", "n", "-", "rich", ")", "and", "poly(a", ")", "or", "poly(t", ")", "regions", "."], "sentence_id": 115, "word_count": 67}, {"text": "thus , we trimmed poly(a ) and poly(t ) sites to minimize the cases in which a test sequence resembles one training set more closely than the other , simply by virtue of having an abundance of the hexamer aaaaaa or tttttt .", "tokens": ["thus", ",", "we", "trimmed", "poly(a", ")", "and", "poly(t", ")", "sites", "to", "minimize", "the", "cases", "in", "which", "a", "test", "sequence", "resembles", "one", "training", "set", "more", "closely", "than", "the", "other", ",", "simply", "by", "virtue", "of", "having", "an", "abundance", "of", "the", "hexamer", "aaaaaa", "or", "tttttt", "."], "sentence_id": 116, "word_count": 43}, {"text": "similarly , test results obtained from short or n - rich sequences can be difficult to interpret .", "tokens": ["similarly", ",", "test", "results", "obtained", "from", "short", "or", "n", "-", "rich", "sequences", "can", "be", "difficult", "to", "interpret", "."], "sentence_id": 117, "word_count": 18}, {"text": "we allowed no more than one n per hexamer and trimmed poly(a ) or poly(t ) tracts longer than 13 nucleotides . to accommodate for possible sequence chimeras ,", "tokens": ["we", "allowed", "no", "more", "than", "one", "n", "per", "hexamer", "and", "trimmed", "poly(a", ")", "or", "poly(t", ")", "tracts", "longer", "than", "13", "nucleotides", ".", "to", "accommodate", "for", "possible", "sequence", "chimeras", ","], "sentence_id": 118, "word_count": 29}, {"text": "those sequences found to contain an internal poly(a ) or poly(t ) segment longer than 13 nucleotides were partitioned into two fragments , and the longer of the two fragments was used in analysis , provided its length was at least 300 nucleotides . after trimming ,", "tokens": ["those", "sequences", "found", "to", "contain", "an", "internal", "poly(a", ")", "or", "poly(t", ")", "segment", "longer", "than", "13", "nucleotides", "were", "partitioned", "into", "two", "fragments", ",", "and", "the", "longer", "of", "the", "two", "fragments", "was", "used", "in", "analysis", ",", "provided", "its", "length", "was", "at", "least", "300", "nucleotides", ".", "after", "trimming", ","], "sentence_id": 119, "word_count": 47}, {"text": "we screened all remaining sequences of 300 nt or longer for similarity to escherichia coli using blastn .", "tokens": ["we", "screened", "all", "remaining", "sequences", "of", "300", "nt", "or", "longer", "for", "similarity", "to", "escherichia", "coli", "using", "blastn", "."], "sentence_id": 120, "word_count": 18}, {"text": "all blast searches used default parameters and low - complexity filtering with the programs dust or seg .", "tokens": ["all", "blast", "searches", "used", "default", "parameters", "and", "low", "-", "complexity", "filtering", "with", "the", "programs", "dust", "or", "seg", "."], "sentence_id": 121, "word_count": 18}, {"text": "the decision to exclude non - coding rna sequences from training sets was informed by the appearance of bimodal distributions of hexamer frequencies and a large degree of overlap between calibration curves ( data not shown ) , likely a result of divergent evolutionary rates between protein - coding and non - coding sequences .", "tokens": ["the", "decision", "to", "exclude", "non", "-", "coding", "rna", "sequences", "from", "training", "sets", "was", "informed", "by", "the", "appearance", "of", "bimodal", "distributions", "of", "hexamer", "frequencies", "and", "a", "large", "degree", "of", "overlap", "between", "calibration", "curves", "(", "data", "not", "shown", ")", ",", "likely", "a", "result", "of", "divergent", "evolutionary", "rates", "between", "protein", "-", "coding", "and", "non", "-", "coding", "sequences", "."], "sentence_id": 122, "word_count": 55}, {"text": "chloroplast and mitochondrial sequences were eliminated to avoid complications due to variation in codon usage between nuclear and organellar genomes .", "tokens": ["chloroplast", "and", "mitochondrial", "sequences", "were", "eliminated", "to", "avoid", "complications", "due", "to", "variation", "in", "codon", "usage", "between", "nuclear", "and", "organellar", "genomes", "."], "sentence_id": 123, "word_count": 21}, {"text": "table 2 summarizes counts of sequences and nucleotides in training sets before and after trimming and screening .", "tokens": ["table", "2", "summarizes", "counts", "of", "sequences", "and", "nucleotides", "in", "training", "sets", "before", "and", "after", "trimming", "and", "screening", "."], "sentence_id": 124, "word_count": 18}, {"text": "to test the validity of word counting as a solution to the problem , we identified a set of 50 gene sequences from plants ( m. truncatula and g. max ) , oomycetes ( phytophthora ) , zygomycetes ( glomus versiforme ) , and bacteria ( sinorhizobium meliloti and agrobacterium tumefaciens ) , for which the function and origin have been characterized experimentally .", "tokens": ["to", "test", "the", "validity", "of", "word", "counting", "as", "a", "solution", "to", "the", "problem", ",", "we", "identified", "a", "set", "of", "50", "gene", "sequences", "from", "plants", "(", "m.", "truncatula", "and", "g.", "max", ")", ",", "oomycetes", "(", "phytophthora", ")", ",", "zygomycetes", "(", "glomus", "versiforme", ")", ",", "and", "bacteria", "(", "sinorhizobium", "meliloti", "and", "agrobacterium", "tumefaciens", ")", ",", "for", "which", "the", "function", "and", "origin", "have", "been", "characterized", "experimentally", "."], "sentence_id": 125, "word_count": 64}, {"text": "we chose genes known to play a role in plant - microbe interactions , as well as genes that are found across taxa .", "tokens": ["we", "chose", "genes", "known", "to", "play", "a", "role", "in", "plant", "-", "microbe", "interactions", ",", "as", "well", "as", "genes", "that", "are", "found", "across", "taxa", "."], "sentence_id": 126, "word_count": 24}, {"text": "we withheld these sequences , and partial transcripts of the same genes , from training sets prior to comparative lexical analysis , and calculated hexamer dissimilarities for each of the three training sets as described below . to diagnose the species of origin for sequences expressed in symbiotic cultures , we collected sequences generated by distinct est sequencing projects from the genbank database .", "tokens": ["we", "withheld", "these", "sequences", ",", "and", "partial", "transcripts", "of", "the", "same", "genes", ",", "from", "training", "sets", "prior", "to", "comparative", "lexical", "analysis", ",", "and", "calculated", "hexamer", "dissimilarities", "for", "each", "of", "the", "three", "training", "sets", "as", "described", "below", ".", "to", "diagnose", "the", "species", "of", "origin", "for", "sequences", "expressed", "in", "symbiotic", "cultures", ",", "we", "collected", "sequences", "generated", "by", "distinct", "est", "sequencing", "projects", "from", "the", "genbank", "database", "."], "sentence_id": 127, "word_count": 64}, {"text": "sequences from pathogenic interactions originated from cultures of a species from the genus phytophthora with its plant host , such as p. sojae and soybean ( g. max ) isolated from inoculated hypocotyls two days after infection   and p. medicaginis and m. truncatula isolated from infected roots 10 days after infection ( c. vance , unpublished data ) .", "tokens": ["sequences", "from", "pathogenic", "interactions", "originated", "from", "cultures", "of", "a", "species", "from", "the", "genus", "phytophthora", "with", "its", "plant", "host", ",", "such", "as", "p.", "sojae", "and", "soybean", "(", "g.", "max", ")", "isolated", "from", "inoculated", "hypocotyls", "two", "days", "after", "infection", "and", "p.", "medicaginis", "and", "m.", "truncatula", "isolated", "from", "infected", "roots", "10", "days", "after", "infection", "(", "c.", "vance", ",", "unpublished", "data", ")", "."], "sentence_id": 128, "word_count": 59}, {"text": "sequences expressed during mutualistic interactions were obtained from cultures with m. truncatula and mycorrhizal ( glomus versiforme ; m.j .", "tokens": ["sequences", "expressed", "during", "mutualistic", "interactions", "were", "obtained", "from", "cultures", "with", "m.", "truncatula", "and", "mycorrhizal", "(", "glomus", "versiforme", ";", "m.j", "."], "sentence_id": 129, "word_count": 20}, {"text": "harrison , unpublished data ) or rhizobacterial ( s. meliloti ; k. vandenbosch , unpublished data ) endosymbionts several days after inoculation .", "tokens": ["harrison", ",", "unpublished", "data", ")", "or", "rhizobacterial", "(", "s.", "meliloti", ";", "k.", "vandenbosch", ",", "unpublished", "data", ")", "endosymbionts", "several", "days", "after", "inoculation", "."], "sentence_id": 130, "word_count": 23}, {"text": "sequences expressed in pure , axenic cultures from p. sojae mycelia and zoospores   and from sterile , uninoculated m. truncatula roots   provided a basis for comparison in which no foreign transcripts were expected . to maximize the reliability of diagnostic comparisons , we screened test sequences for high quality as for training sequences , and for low similarity to e. coli , chloroplast and mitochondrial genes , and non - coding rna transcripts ( ribosomal and transfer rnas ) .", "tokens": ["sequences", "expressed", "in", "pure", ",", "axenic", "cultures", "from", "p.", "sojae", "mycelia", "and", "zoospores", "and", "from", "sterile", ",", "uninoculated", "m.", "truncatula", "roots", "provided", "a", "basis", "for", "comparison", "in", "which", "no", "foreign", "transcripts", "were", "expected", ".", "to", "maximize", "the", "reliability", "of", "diagnostic", "comparisons", ",", "we", "screened", "test", "sequences", "for", "high", "quality", "as", "for", "training", "sequences", ",", "and", "for", "low", "similarity", "to", "e.", "coli", ",", "chloroplast", "and", "mitochondrial", "genes", ",", "and", "non", "-", "coding", "rna", "transcripts", "(", "ribosomal", "and", "transfer", "rnas", ")", "."], "sentence_id": 131, "word_count": 80}, {"text": "independent blastn comparisons identified sequences having very high similarity ( e < 10 ) to vector sequences or moderately high similarity ( e < 10 ) to non - nuclear or non - coding sequences obtained from genbank .", "tokens": ["independent", "blastn", "comparisons", "identified", "sequences", "having", "very", "high", "similarity", "(", "e", "<", "10", ")", "to", "vector", "sequences", "or", "moderately", "high", "similarity", "(", "e", "<", "10", ")", "to", "non", "-", "nuclear", "or", "non", "-", "coding", "sequences", "obtained", "from", "genbank", "."], "sentence_id": 132, "word_count": 39}, {"text": "we wrote a perl program ( countgc.pl ) that calculates the gc base content of a sequence as the portion of guanine and cytosine residues among all unambiguous ( non - n ) nucleotides in a sequence . the hist method in r ,", "tokens": ["we", "wrote", "a", "perl", "program", "(", "countgc.pl", ")", "that", "calculates", "the", "gc", "base", "content", "of", "a", "sequence", "as", "the", "portion", "of", "guanine", "and", "cytosine", "residues", "among", "all", "unambiguous", "(", "non", "-", "n", ")", "nucleotides", "in", "a", "sequence", ".", "the", "hist", "method", "in", "r", ","], "sentence_id": 133, "word_count": 44}, {"text": "version 1.1.1   aggregated continuous percentages into discrete histogram bins , using bin sizes of 2% difference in gc , with inclusive lower bin boundaries and exclusive upper bounds ; the lm method tested for linear correlation of the dissimilarity test statistic t with gc .", "tokens": ["version", "1.1.1", "aggregated", "continuous", "percentages", "into", "discrete", "histogram", "bins", ",", "using", "bin", "sizes", "of", "2%", "difference", "in", "gc", ",", "with", "inclusive", "lower", "bin", "boundaries", "and", "exclusive", "upper", "bounds", ";", "the", "lm", "method", "tested", "for", "linear", "correlation", "of", "the", "dissimilarity", "test", "statistic", "t", "with", "gc", "."], "sentence_id": 134, "word_count": 45}, {"text": "used a likelihood - ratio test to determine whether word frequencies from a particular sequence more closely resemble the frequency distribution of control data sets from the taxon being sequenced or a distantly related outgroup .", "tokens": ["used", "a", "likelihood", "-", "ratio", "test", "to", "determine", "whether", "word", "frequencies", "from", "a", "particular", "sequence", "more", "closely", "resemble", "the", "frequency", "distribution", "of", "control", "data", "sets", "from", "the", "taxon", "being", "sequenced", "or", "a", "distantly", "related", "outgroup", "."], "sentence_id": 135, "word_count": 36}, {"text": "they computed a test statistic t(a , b , x ) for each sequence x as the difference of log - likelihood ratio dissimilarity measures , d(a , x ) = -2log(a , x ) , for two data sets , a control set a and an outgroup b , such that t(a , b , x ) = d(a , x ) - d(b , x ) .", "tokens": ["they", "computed", "a", "test", "statistic", "t(a", ",", "b", ",", "x", ")", "for", "each", "sequence", "x", "as", "the", "difference", "of", "log", "-", "likelihood", "ratio", "dissimilarity", "measures", ",", "d(a", ",", "x", ")", "=", "-2log(a", ",", "x", ")", ",", "for", "two", "data", "sets", ",", "a", "control", "set", "a", "and", "an", "outgroup", "b", ",", "such", "that", "t(a", ",", "b", ",", "x", ")", "=", "d(a", ",", "x", ")", "-", "d(b", ",", "x", ")", "."], "sentence_id": 136, "word_count": 69}, {"text": "a negative value for t indicates that the sequence more closely resembles words from a ; conversely , a positive value indicates a likely contaminant related to b. ( dissimilarity is conceptually related to distance . however , dissimilarity does not measure distance because it does not possess the mathematical properties of a distance metric . ) unlike the calculation of calibration curves , in which 300-nucleotide subsequences are randomly resampled , hexamer dissimilarity is measured over the whole length of a test sequence when inferring a transcript 's origin .", "tokens": ["a", "negative", "value", "for", "t", "indicates", "that", "the", "sequence", "more", "closely", "resembles", "words", "from", "a", ";", "conversely", ",", "a", "positive", "value", "indicates", "a", "likely", "contaminant", "related", "to", "b.", "(", "dissimilarity", "is", "conceptually", "related", "to", "distance", ".", "however", ",", "dissimilarity", "does", "not", "measure", "distance", "because", "it", "does", "not", "possess", "the", "mathematical", "properties", "of", "a", "distance", "metric", ".", ")", "unlike", "the", "calculation", "of", "calibration", "curves", ",", "in", "which", "300-nucleotide", "subsequences", "are", "randomly", "resampled", ",", "hexamer", "dissimilarity", "is", "measured", "over", "the", "whole", "length", "of", "a", "test", "sequence", "when", "inferring", "a", "transcript", "'s", "origin", "."], "sentence_id": 137, "word_count": 91}, {"text": "originally , the investigators used the null hypothesis that no difference exists for dissimilarity measures between the two data sets , or that t(a , b , x ) = 0 .", "tokens": ["originally", ",", "the", "investigators", "used", "the", "null", "hypothesis", "that", "no", "difference", "exists", "for", "dissimilarity", "measures", "between", "the", "two", "data", "sets", ",", "or", "that", "t(a", ",", "b", ",", "x", ")", "=", "0", "."], "sentence_id": 138, "word_count": 32}, {"text": "tested two alternative hypotheses : that t < 0 , being more like a , or t > 0 , like b. lexical analysis using pentamers or heptamers yields similar error rates and very highly correlated values for the test result ( not shown ) . because white et al .  ", "tokens": ["tested", "two", "alternative", "hypotheses", ":", "that", "t", "<", "0", ",", "being", "more", "like", "a", ",", "or", "t", ">", "0", ",", "like", "b.", "lexical", "analysis", "using", "pentamers", "or", "heptamers", "yields", "similar", "error", "rates", "and", "very", "highly", "correlated", "values", "for", "the", "test", "result", "(", "not", "shown", ")", ".", "because", "white", "et", "al", "."], "sentence_id": 139, "word_count": 51}, {"text": "reported the best results were obtained using hexamers , and because a word size of six nucleotides corresponds to the size of a dicodon , we chose to analyze hexamer frequencies . to use longer words", "tokens": ["reported", "the", "best", "results", "were", "obtained", "using", "hexamers", ",", "and", "because", "a", "word", "size", "of", "six", "nucleotides", "corresponds", "to", "the", "size", "of", "a", "dicodon", ",", "we", "chose", "to", "analyze", "hexamer", "frequencies", ".", "to", "use", "longer", "words"], "sentence_id": 140, "word_count": 36}, {"text": "requires more training data , because the number of possible words increases exponentially with increasing word size .", "tokens": ["requires", "more", "training", "data", ",", "because", "the", "number", "of", "possible", "words", "increases", "exponentially", "with", "increasing", "word", "size", "."], "sentence_id": 141, "word_count": 18}, {"text": "use of shorter words may be adequate for some applications and will be investigated in future work . though we used white 's word - counting methods , we did make slight modifications .", "tokens": ["use", "of", "shorter", "words", "may", "be", "adequate", "for", "some", "applications", "and", "will", "be", "investigated", "in", "future", "work", ".", "though", "we", "used", "white", "'s", "word", "-", "counting", "methods", ",", "we", "did", "make", "slight", "modifications", "."], "sentence_id": 142, "word_count": 34}, {"text": "we simplified one program ( called hybridize ) to compute individual dissimilarity values , rather than paired differences ; a patch that details how to modify the c program is available ( see hyb2dis.txt in additional data files ) .", "tokens": ["we", "simplified", "one", "program", "(", "called", "hybridize", ")", "to", "compute", "individual", "dissimilarity", "values", ",", "rather", "than", "paired", "differences", ";", "a", "patch", "that", "details", "how", "to", "modify", "the", "c", "program", "is", "available", "(", "see", "hyb2dis.txt", "in", "additional", "data", "files", ")", "."], "sentence_id": 143, "word_count": 40}, {"text": "more importantly , we amended the null hypothesis and interpreted calibration curves to test for statistically significant dissimilarity differences . though the likelihood - ratio test statistic indicates the magnitude of similarity to a or b , we do not know what values for t are significant with known confidence .", "tokens": ["more", "importantly", ",", "we", "amended", "the", "null", "hypothesis", "and", "interpreted", "calibration", "curves", "to", "test", "for", "statistically", "significant", "dissimilarity", "differences", ".", "though", "the", "likelihood", "-", "ratio", "test", "statistic", "indicates", "the", "magnitude", "of", "similarity", "to", "a", "or", "b", ",", "we", "do", "not", "know", "what", "values", "for", "t", "are", "significant", "with", "known", "confidence", "."], "sentence_id": 144, "word_count": 51}, {"text": "when testing hypotheses , one can make two types of error : type i , or false positives , and type ii , false negatives .", "tokens": ["when", "testing", "hypotheses", ",", "one", "can", "make", "two", "types", "of", "error", ":", "type", "i", ",", "or", "false", "positives", ",", "and", "type", "ii", ",", "false", "negatives", "."], "sentence_id": 145, "word_count": 26}, {"text": "the false - positive rate is denoted  and false - negative rate . we determine  and  from overlap in the calibration curves . inferring error rates from calibration curves", "tokens": ["the", "false", "-", "positive", "rate", "is", "denoted", "and", "false", "-", "negative", "rate", ".", "we", "determine", "and", "from", "overlap", "in", "the", "calibration", "curves", ".", "inferring", "error", "rates", "from", "calibration", "curves"], "sentence_id": 146, "word_count": 29}, {"text": "is justified because we know the correct answer and determine the error rate via resampling , as with bootstrap methods to infer error rates or confidence intervals .", "tokens": ["is", "justified", "because", "we", "know", "the", "correct", "answer", "and", "determine", "the", "error", "rate", "via", "resampling", ",", "as", "with", "bootstrap", "methods", "to", "infer", "error", "rates", "or", "confidence", "intervals", "."], "sentence_id": 147, "word_count": 28}, {"text": "we are interested in knowing from which of two organisms a sequence originated , and are reasonably confident that it came from either one or the other .", "tokens": ["we", "are", "interested", "in", "knowing", "from", "which", "of", "two", "organisms", "a", "sequence", "originated", ",", "and", "are", "reasonably", "confident", "that", "it", "came", "from", "either", "one", "or", "the", "other", "."], "sentence_id": 148, "word_count": 28}, {"text": "thus , we assume it came from one and test whether we have evidence to refute this assumption .", "tokens": ["thus", ",", "we", "assume", "it", "came", "from", "one", "and", "test", "whether", "we", "have", "evidence", "to", "refute", "this", "assumption", "."], "sentence_id": 149, "word_count": 19}, {"text": "the null hypothesis here is that sequence x is from a. alternatively , it might be from b. evaluating the calibration curve overlap at t = 0 quantifies the associated error rates .", "tokens": ["the", "null", "hypothesis", "here", "is", "that", "sequence", "x", "is", "from", "a.", "alternatively", ",", "it", "might", "be", "from", "b.", "evaluating", "the", "calibration", "curve", "overlap", "at", "t", "=", "0", "quantifies", "the", "associated", "error", "rates", "."], "sentence_id": 150, "word_count": 33}, {"text": "the cumulative distribution function ( cdf ) of taxon b specifies  where cdfb intersects 0 ; the cdf from a specifies  as 1-cdfa(0 )", "tokens": ["the", "cumulative", "distribution", "function", "(", "cdf", ")", "of", "taxon", "b", "specifies", "where", "cdfb", "intersects", "0", ";", "the", "cdf", "from", "a", "specifies", "as", "1-cdfa(0", ")"], "sentence_id": 151, "word_count": 24}, {"text": ". we can thus resolve the problem with known confidence p : p ( t > 0 ) = . all other computations were performed as described previously .", "tokens": [".", "we", "can", "thus", "resolve", "the", "problem", "with", "known", "confidence", "p", ":", "p", "(", "t", ">", "0", ")", "=", ".", "all", "other", "computations", "were", "performed", "as", "described", "previously", "."], "sentence_id": 152, "word_count": 29}, {"text": "software used for lexical analysis was obtained via anonymous ftp from the tigr software ftp site .", "tokens": ["software", "used", "for", "lexical", "analysis", "was", "obtained", "via", "anonymous", "ftp", "from", "the", "tigr", "software", "ftp", "site", "."], "sentence_id": 153, "word_count": 17}, {"text": "to characterize hexamer frequencies in plant hosts and their microbial symbionts , we collected sets of training sequences from public databases and edited them for quality .", "tokens": ["to", "characterize", "hexamer", "frequencies", "in", "plant", "hosts", "and", "their", "microbial", "symbionts", ",", "we", "collected", "sets", "of", "training", "sequences", "from", "public", "databases", "and", "edited", "them", "for", "quality", "."], "sentence_id": 154, "word_count": 27}, {"text": "training sets were chosen to be representative of , but obtained independently from , taxa participating in symbiotic associations for which a diagnosis of origin would be made . because the species being compared are represented unevenly in public sequence databases , taxa were chosen so that roughly the same number of genes were analyzed in each training set , rather than simply to maximize the numbers of species or sequences present .", "tokens": ["training", "sets", "were", "chosen", "to", "be", "representative", "of", ",", "but", "obtained", "independently", "from", ",", "taxa", "participating", "in", "symbiotic", "associations", "for", "which", "a", "diagnosis", "of", "origin", "would", "be", "made", ".", "because", "the", "species", "being", "compared", "are", "represented", "unevenly", "in", "public", "sequence", "databases", ",", "taxa", "were", "chosen", "so", "that", "roughly", "the", "same", "number", "of", "genes", "were", "analyzed", "in", "each", "training", "set", ",", "rather", "than", "simply", "to", "maximize", "the", "numbers", "of", "species", "or", "sequences", "present", "."], "sentence_id": 155, "word_count": 73}, {"text": "training sets represent protein - coding sequences from three taxonomic groupings : plants ( a1 , medicago and glycine spp . ) , either fungi ( b2 , zygomycetes and chytridiomycetes ) or stramenopiles ( b1 ) , including ests from p. infestans , and bacteria ( b3 , rhizobium , sinorhizobium and bradyrhizobium ) .", "tokens": ["training", "sets", "represent", "protein", "-", "coding", "sequences", "from", "three", "taxonomic", "groupings", ":", "plants", "(", "a1", ",", "medicago", "and", "glycine", "spp", ".", ")", ",", "either", "fungi", "(", "b2", ",", "zygomycetes", "and", "chytridiomycetes", ")", "or", "stramenopiles", "(", "b1", ")", ",", "including", "ests", "from", "p.", "infestans", ",", "and", "bacteria", "(", "b3", ",", "rhizobium", ",", "sinorhizobium", "and", "bradyrhizobium", ")", "."], "sentence_id": 156, "word_count": 56}, {"text": "we performed pairwise comparisons with two different , taxon - specific training sets ( a and b ) to infer the origin of a transcript .", "tokens": ["we", "performed", "pairwise", "comparisons", "with", "two", "different", ",", "taxon", "-", "specific", "training", "sets", "(", "a", "and", "b", ")", "to", "infer", "the", "origin", "of", "a", "transcript", "."], "sentence_id": 157, "word_count": 26}, {"text": "training sets were obtained by querying the genbank database using the entrez retrieval tool . a preliminary query by taxon name obtained all available nucleotide sequences from that taxon , then the limits option excluded ests , stss ( sequence - tagged sites ) , gsss ( genome survey sequences ) , working draft sequences , and patented sequences from the query set . organellar ( mitochondrial and chloroplast ) dna was also excluded via the limits option .", "tokens": ["training", "sets", "were", "obtained", "by", "querying", "the", "genbank", "database", "using", "the", "entrez", "retrieval", "tool", ".", "a", "preliminary", "query", "by", "taxon", "name", "obtained", "all", "available", "nucleotide", "sequences", "from", "that", "taxon", ",", "then", "the", "limits", "option", "excluded", "ests", ",", "stss", "(", "sequence", "-", "tagged", "sites", ")", ",", "gsss", "(", "genome", "survey", "sequences", ")", ",", "working", "draft", "sequences", ",", "and", "patented", "sequences", "from", "the", "query", "set", ".", "organellar", "(", "mitochondrial", "and", "chloroplast", ")", "dna", "was", "also", "excluded", "via", "the", "limits", "option", "."], "sentence_id": 158, "word_count": 79}, {"text": "a query term to require that a sequence contain a protein - coding region ( cds ) was also added , which excluded ribosomal and transfer rna sequences .", "tokens": ["a", "query", "term", "to", "require", "that", "a", "sequence", "contain", "a", "protein", "-", "coding", "region", "(", "cds", ")", "was", "also", "added", ",", "which", "excluded", "ribosomal", "and", "transfer", "rna", "sequences", "."], "sentence_id": 159, "word_count": 29}, {"text": "the results consisted of all sequences that contain a nuclear protein - coding sequence available for that taxon at the time of the query .", "tokens": ["the", "results", "consisted", "of", "all", "sequences", "that", "contain", "a", "nuclear", "protein", "-", "coding", "sequence", "available", "for", "that", "taxon", "at", "the", "time", "of", "the", "query", "."], "sentence_id": 160, "word_count": 25}, {"text": "( changing slightly the composition of training sets between those dates did not notably affect the experimental outcome . ) following a previously established protocol , we used a resampling procedure to evaluate the degree of overlap between distributions of hexamer composition obtained from comparing two training sets . in this protocol", "tokens": ["(", "changing", "slightly", "the", "composition", "of", "training", "sets", "between", "those", "dates", "did", "not", "notably", "affect", "the", "experimental", "outcome", ".", ")", "following", "a", "previously", "established", "protocol", ",", "we", "used", "a", "resampling", "procedure", "to", "evaluate", "the", "degree", "of", "overlap", "between", "distributions", "of", "hexamer", "composition", "obtained", "from", "comparing", "two", "training", "sets", ".", "in", "this", "protocol"], "sentence_id": 161, "word_count": 52}, {"text": ", we resampled each training set 40 times by random partitioning into training ( for hexamer counts ) and test calculation pools . to control for any bias introduced by length variation ,", "tokens": [",", "we", "resampled", "each", "training", "set", "40", "times", "by", "random", "partitioning", "into", "training", "(", "for", "hexamer", "counts", ")", "and", "test", "calculation", "pools", ".", "to", "control", "for", "any", "bias", "introduced", "by", "length", "variation", ","], "sentence_id": 162, "word_count": 33}, {"text": "a program randomly clipped 300 nucleotide fragments for word counting . as a result , one random 300 nucleotide fragment from each training sequence was present in the training set during a single resampling replicate ; independent replicates contained different , randomly chosen training sequences and 300 nucleotide fragments .", "tokens": ["a", "program", "randomly", "clipped", "300", "nucleotide", "fragments", "for", "word", "counting", ".", "as", "a", "result", ",", "one", "random", "300", "nucleotide", "fragment", "from", "each", "training", "sequence", "was", "present", "in", "the", "training", "set", "during", "a", "single", "resampling", "replicate", ";", "independent", "replicates", "contained", "different", ",", "randomly", "chosen", "training", "sequences", "and", "300", "nucleotide", "fragments", "."], "sentence_id": 163, "word_count": 50}, {"text": "values of the test statistic from 40 resampled replicates were pooled for calibration purposes . as with the original protocol , we pooled the resulting test statistic distributions , normalized them as cumulative distributions , and then evaluated them for overlap .", "tokens": ["values", "of", "the", "test", "statistic", "from", "40", "resampled", "replicates", "were", "pooled", "for", "calibration", "purposes", ".", "as", "with", "the", "original", "protocol", ",", "we", "pooled", "the", "resulting", "test", "statistic", "distributions", ",", "normalized", "them", "as", "cumulative", "distributions", ",", "and", "then", "evaluated", "them", "for", "overlap", "."], "sentence_id": 164, "word_count": 42}, {"text": "we call the resulting comparisons ' calibration curves ' , as they are not used directly to make inferences , but rather indirectly , to evaluate the degree of separation in hexamer counts from different taxa", "tokens": ["we", "call", "the", "resulting", "comparisons", "'", "calibration", "curves", "'", ",", "as", "they", "are", "not", "used", "directly", "to", "make", "inferences", ",", "but", "rather", "indirectly", ",", "to", "evaluate", "the", "degree", "of", "separation", "in", "hexamer", "counts", "from", "different", "taxa"], "sentence_id": 165, "word_count": 36}, {"text": ". overlap of calibration curves should be minimal to yield the most statistically powerful results possible .", "tokens": [".", "overlap", "of", "calibration", "curves", "should", "be", "minimal", "to", "yield", "the", "most", "statistically", "powerful", "results", "possible", "."], "sentence_id": 166, "word_count": 17}, {"text": "due to considerable overlap of calibration curves between taxonomically general , inclusive training sets ( that is , all eudicots , all fungi and miscellaneous eukaryotes , and all eubacteria , data not shown ) , we opted to work with specific training sets that included only the most species - specific sequences available , while maintaining approximately equal sample sizes across taxa .", "tokens": ["due", "to", "considerable", "overlap", "of", "calibration", "curves", "between", "taxonomically", "general", ",", "inclusive", "training", "sets", "(", "that", "is", ",", "all", "eudicots", ",", "all", "fungi", "and", "miscellaneous", "eukaryotes", ",", "and", "all", "eubacteria", ",", "data", "not", "shown", ")", ",", "we", "opted", "to", "work", "with", "specific", "training", "sets", "that", "included", "only", "the", "most", "species", "-", "specific", "sequences", "available", ",", "while", "maintaining", "approximately", "equal", "sample", "sizes", "across", "taxa", "."], "sentence_id": 167, "word_count": 64}, {"text": "the most challenging case was that of the arbuscular mycorrhizal fungi , for which very few protein - coding sequences are available . to increase the amount of data in this training set ( b2 ) without biasing sample sizes , we pooled sequences from all species in the zygomycetes with all available chytridiomycete coding sequences , and compared this training set with a set from a single plant genus , medicago ( a2 ) .", "tokens": ["the", "most", "challenging", "case", "was", "that", "of", "the", "arbuscular", "mycorrhizal", "fungi", ",", "for", "which", "very", "few", "protein", "-", "coding", "sequences", "are", "available", ".", "to", "increase", "the", "amount", "of", "data", "in", "this", "training", "set", "(", "b2", ")", "without", "biasing", "sample", "sizes", ",", "we", "pooled", "sequences", "from", "all", "species", "in", "the", "zygomycetes", "with", "all", "available", "chytridiomycete", "coding", "sequences", ",", "and", "compared", "this", "training", "set", "with", "a", "set", "from", "a", "single", "plant", "genus", ",", "medicago", "(", "a2", ")", "."], "sentence_id": 168, "word_count": 76}, {"text": "we chose this option , rather than including an arbitrary subset of sequences from the ascomycetes and basidiomycetes , because zygomycetes and chytridiomycetes have diverged from their common ancestor less recently than the ascomycetes and basidiomycetes , based on 18s ribosomal rna sequence data .", "tokens": ["we", "chose", "this", "option", ",", "rather", "than", "including", "an", "arbitrary", "subset", "of", "sequences", "from", "the", "ascomycetes", "and", "basidiomycetes", ",", "because", "zygomycetes", "and", "chytridiomycetes", "have", "diverged", "from", "their", "common", "ancestor", "less", "recently", "than", "the", "ascomycetes", "and", "basidiomycetes", ",", "based", "on", "18s", "ribosomal", "rna", "sequence", "data", "."], "sentence_id": 169, "word_count": 45}, {"text": "that is , the ascomycetes and basidiomycetes are more highly derived from the common fungal ancestor than zygomycetes and chytridiomycetes , which resemble more closely the ancestral state in modern lineages . starting with a full set of sequences , we filtered for high - quality sequences by trimming regions having extensive ambiguous bases ( n - rich ) and poly(a ) or poly(t ) regions .", "tokens": ["that", "is", ",", "the", "ascomycetes", "and", "basidiomycetes", "are", "more", "highly", "derived", "from", "the", "common", "fungal", "ancestor", "than", "zygomycetes", "and", "chytridiomycetes", ",", "which", "resemble", "more", "closely", "the", "ancestral", "state", "in", "modern", "lineages", ".", "starting", "with", "a", "full", "set", "of", "sequences", ",", "we", "filtered", "for", "high", "-", "quality", "sequences", "by", "trimming", "regions", "having", "extensive", "ambiguous", "bases", "(", "n", "-", "rich", ")", "and", "poly(a", ")", "or", "poly(t", ")", "regions", "."], "sentence_id": 170, "word_count": 67}, {"text": "thus , we trimmed poly(a ) and poly(t ) sites to minimize the cases in which a test sequence resembles one training set more closely than the other , simply by virtue of having an abundance of the hexamer aaaaaa or tttttt .", "tokens": ["thus", ",", "we", "trimmed", "poly(a", ")", "and", "poly(t", ")", "sites", "to", "minimize", "the", "cases", "in", "which", "a", "test", "sequence", "resembles", "one", "training", "set", "more", "closely", "than", "the", "other", ",", "simply", "by", "virtue", "of", "having", "an", "abundance", "of", "the", "hexamer", "aaaaaa", "or", "tttttt", "."], "sentence_id": 171, "word_count": 43}, {"text": "similarly , test results obtained from short or n - rich sequences can be difficult to interpret .", "tokens": ["similarly", ",", "test", "results", "obtained", "from", "short", "or", "n", "-", "rich", "sequences", "can", "be", "difficult", "to", "interpret", "."], "sentence_id": 172, "word_count": 18}, {"text": "we allowed no more than one n per hexamer and trimmed poly(a ) or poly(t ) tracts longer than 13 nucleotides . to accommodate for possible sequence chimeras ,", "tokens": ["we", "allowed", "no", "more", "than", "one", "n", "per", "hexamer", "and", "trimmed", "poly(a", ")", "or", "poly(t", ")", "tracts", "longer", "than", "13", "nucleotides", ".", "to", "accommodate", "for", "possible", "sequence", "chimeras", ","], "sentence_id": 173, "word_count": 29}, {"text": "those sequences found to contain an internal poly(a ) or poly(t ) segment longer than 13 nucleotides were partitioned into two fragments , and the longer of the two fragments was used in analysis , provided its length was at least 300 nucleotides . after trimming ,", "tokens": ["those", "sequences", "found", "to", "contain", "an", "internal", "poly(a", ")", "or", "poly(t", ")", "segment", "longer", "than", "13", "nucleotides", "were", "partitioned", "into", "two", "fragments", ",", "and", "the", "longer", "of", "the", "two", "fragments", "was", "used", "in", "analysis", ",", "provided", "its", "length", "was", "at", "least", "300", "nucleotides", ".", "after", "trimming", ","], "sentence_id": 174, "word_count": 47}, {"text": "we screened all remaining sequences of 300 nt or longer for similarity to escherichia coli using blastn .", "tokens": ["we", "screened", "all", "remaining", "sequences", "of", "300", "nt", "or", "longer", "for", "similarity", "to", "escherichia", "coli", "using", "blastn", "."], "sentence_id": 175, "word_count": 18}, {"text": "all blast searches used default parameters and low - complexity filtering with the programs dust or seg .", "tokens": ["all", "blast", "searches", "used", "default", "parameters", "and", "low", "-", "complexity", "filtering", "with", "the", "programs", "dust", "or", "seg", "."], "sentence_id": 176, "word_count": 18}, {"text": "the decision to exclude non - coding rna sequences from training sets was informed by the appearance of bimodal distributions of hexamer frequencies and a large degree of overlap between calibration curves ( data not shown ) , likely a result of divergent evolutionary rates between protein - coding and non - coding sequences .", "tokens": ["the", "decision", "to", "exclude", "non", "-", "coding", "rna", "sequences", "from", "training", "sets", "was", "informed", "by", "the", "appearance", "of", "bimodal", "distributions", "of", "hexamer", "frequencies", "and", "a", "large", "degree", "of", "overlap", "between", "calibration", "curves", "(", "data", "not", "shown", ")", ",", "likely", "a", "result", "of", "divergent", "evolutionary", "rates", "between", "protein", "-", "coding", "and", "non", "-", "coding", "sequences", "."], "sentence_id": 177, "word_count": 55}, {"text": "chloroplast and mitochondrial sequences were eliminated to avoid complications due to variation in codon usage between nuclear and organellar genomes .", "tokens": ["chloroplast", "and", "mitochondrial", "sequences", "were", "eliminated", "to", "avoid", "complications", "due", "to", "variation", "in", "codon", "usage", "between", "nuclear", "and", "organellar", "genomes", "."], "sentence_id": 178, "word_count": 21}, {"text": "table 2 summarizes counts of sequences and nucleotides in training sets before and after trimming and screening .", "tokens": ["table", "2", "summarizes", "counts", "of", "sequences", "and", "nucleotides", "in", "training", "sets", "before", "and", "after", "trimming", "and", "screening", "."], "sentence_id": 179, "word_count": 18}, {"text": "to test the validity of word counting as a solution to the problem , we identified a set of 50 gene sequences from plants ( m. truncatula and g. max ) , oomycetes ( phytophthora ) , zygomycetes ( glomus versiforme ) , and bacteria ( sinorhizobium meliloti and agrobacterium tumefaciens ) , for which the function and origin have been characterized experimentally .", "tokens": ["to", "test", "the", "validity", "of", "word", "counting", "as", "a", "solution", "to", "the", "problem", ",", "we", "identified", "a", "set", "of", "50", "gene", "sequences", "from", "plants", "(", "m.", "truncatula", "and", "g.", "max", ")", ",", "oomycetes", "(", "phytophthora", ")", ",", "zygomycetes", "(", "glomus", "versiforme", ")", ",", "and", "bacteria", "(", "sinorhizobium", "meliloti", "and", "agrobacterium", "tumefaciens", ")", ",", "for", "which", "the", "function", "and", "origin", "have", "been", "characterized", "experimentally", "."], "sentence_id": 180, "word_count": 64}, {"text": "we chose genes known to play a role in plant - microbe interactions , as well as genes that are found across taxa .", "tokens": ["we", "chose", "genes", "known", "to", "play", "a", "role", "in", "plant", "-", "microbe", "interactions", ",", "as", "well", "as", "genes", "that", "are", "found", "across", "taxa", "."], "sentence_id": 181, "word_count": 24}, {"text": "we withheld these sequences , and partial transcripts of the same genes , from training sets prior to comparative lexical analysis , and calculated hexamer dissimilarities for each of the three training sets as described below .", "tokens": ["we", "withheld", "these", "sequences", ",", "and", "partial", "transcripts", "of", "the", "same", "genes", ",", "from", "training", "sets", "prior", "to", "comparative", "lexical", "analysis", ",", "and", "calculated", "hexamer", "dissimilarities", "for", "each", "of", "the", "three", "training", "sets", "as", "described", "below", "."], "sentence_id": 182, "word_count": 37}, {"text": "to characterize hexamer frequencies in plant hosts and their microbial symbionts , we collected sets of training sequences from public databases and edited them for quality .", "tokens": ["to", "characterize", "hexamer", "frequencies", "in", "plant", "hosts", "and", "their", "microbial", "symbionts", ",", "we", "collected", "sets", "of", "training", "sequences", "from", "public", "databases", "and", "edited", "them", "for", "quality", "."], "sentence_id": 183, "word_count": 27}, {"text": "training sets were chosen to be representative of , but obtained independently from , taxa participating in symbiotic associations for which a diagnosis of origin would be made . because the species being compared are represented unevenly in public sequence databases , taxa were chosen so that roughly the same number of genes were analyzed in each training set , rather than simply to maximize the numbers of species or sequences present .", "tokens": ["training", "sets", "were", "chosen", "to", "be", "representative", "of", ",", "but", "obtained", "independently", "from", ",", "taxa", "participating", "in", "symbiotic", "associations", "for", "which", "a", "diagnosis", "of", "origin", "would", "be", "made", ".", "because", "the", "species", "being", "compared", "are", "represented", "unevenly", "in", "public", "sequence", "databases", ",", "taxa", "were", "chosen", "so", "that", "roughly", "the", "same", "number", "of", "genes", "were", "analyzed", "in", "each", "training", "set", ",", "rather", "than", "simply", "to", "maximize", "the", "numbers", "of", "species", "or", "sequences", "present", "."], "sentence_id": 184, "word_count": 73}, {"text": "training sets represent protein - coding sequences from three taxonomic groupings : plants ( a1 , medicago and glycine spp . ) , either fungi ( b2 , zygomycetes and chytridiomycetes ) or stramenopiles ( b1 ) , including ests from p. infestans , and bacteria ( b3 , rhizobium , sinorhizobium and bradyrhizobium ) .", "tokens": ["training", "sets", "represent", "protein", "-", "coding", "sequences", "from", "three", "taxonomic", "groupings", ":", "plants", "(", "a1", ",", "medicago", "and", "glycine", "spp", ".", ")", ",", "either", "fungi", "(", "b2", ",", "zygomycetes", "and", "chytridiomycetes", ")", "or", "stramenopiles", "(", "b1", ")", ",", "including", "ests", "from", "p.", "infestans", ",", "and", "bacteria", "(", "b3", ",", "rhizobium", ",", "sinorhizobium", "and", "bradyrhizobium", ")", "."], "sentence_id": 185, "word_count": 56}, {"text": "we performed pairwise comparisons with two different , taxon - specific training sets ( a and b ) to infer the origin of a transcript .", "tokens": ["we", "performed", "pairwise", "comparisons", "with", "two", "different", ",", "taxon", "-", "specific", "training", "sets", "(", "a", "and", "b", ")", "to", "infer", "the", "origin", "of", "a", "transcript", "."], "sentence_id": 186, "word_count": 26}, {"text": "training sets were obtained by querying the genbank database using the entrez retrieval tool . a preliminary query by taxon name obtained all available nucleotide sequences from that taxon , then the limits option excluded ests , stss ( sequence - tagged sites ) , gsss ( genome survey sequences ) , working draft sequences , and patented sequences from the query set . organellar ( mitochondrial and chloroplast ) dna was also excluded via the limits option .", "tokens": ["training", "sets", "were", "obtained", "by", "querying", "the", "genbank", "database", "using", "the", "entrez", "retrieval", "tool", ".", "a", "preliminary", "query", "by", "taxon", "name", "obtained", "all", "available", "nucleotide", "sequences", "from", "that", "taxon", ",", "then", "the", "limits", "option", "excluded", "ests", ",", "stss", "(", "sequence", "-", "tagged", "sites", ")", ",", "gsss", "(", "genome", "survey", "sequences", ")", ",", "working", "draft", "sequences", ",", "and", "patented", "sequences", "from", "the", "query", "set", ".", "organellar", "(", "mitochondrial", "and", "chloroplast", ")", "dna", "was", "also", "excluded", "via", "the", "limits", "option", "."], "sentence_id": 187, "word_count": 79}, {"text": "a query term to require that a sequence contain a protein - coding region ( cds ) was also added , which excluded ribosomal and transfer rna sequences .", "tokens": ["a", "query", "term", "to", "require", "that", "a", "sequence", "contain", "a", "protein", "-", "coding", "region", "(", "cds", ")", "was", "also", "added", ",", "which", "excluded", "ribosomal", "and", "transfer", "rna", "sequences", "."], "sentence_id": 188, "word_count": 29}, {"text": "the results consisted of all sequences that contain a nuclear protein - coding sequence available for that taxon at the time of the query .", "tokens": ["the", "results", "consisted", "of", "all", "sequences", "that", "contain", "a", "nuclear", "protein", "-", "coding", "sequence", "available", "for", "that", "taxon", "at", "the", "time", "of", "the", "query", "."], "sentence_id": 189, "word_count": 25}, {"text": "( changing slightly the composition of training sets between those dates did not notably affect the experimental outcome . ) following a previously established protocol , we used a resampling procedure to evaluate the degree of overlap between distributions of hexamer composition obtained from comparing two training sets . in this protocol", "tokens": ["(", "changing", "slightly", "the", "composition", "of", "training", "sets", "between", "those", "dates", "did", "not", "notably", "affect", "the", "experimental", "outcome", ".", ")", "following", "a", "previously", "established", "protocol", ",", "we", "used", "a", "resampling", "procedure", "to", "evaluate", "the", "degree", "of", "overlap", "between", "distributions", "of", "hexamer", "composition", "obtained", "from", "comparing", "two", "training", "sets", ".", "in", "this", "protocol"], "sentence_id": 190, "word_count": 52}, {"text": ", we resampled each training set 40 times by random partitioning into training ( for hexamer counts ) and test calculation pools . to control for any bias introduced by length variation ,", "tokens": [",", "we", "resampled", "each", "training", "set", "40", "times", "by", "random", "partitioning", "into", "training", "(", "for", "hexamer", "counts", ")", "and", "test", "calculation", "pools", ".", "to", "control", "for", "any", "bias", "introduced", "by", "length", "variation", ","], "sentence_id": 191, "word_count": 33}, {"text": "a program randomly clipped 300 nucleotide fragments for word counting . as a result , one random 300 nucleotide fragment from each training sequence was present in the training set during a single resampling replicate ; independent replicates contained different , randomly chosen training sequences and 300 nucleotide fragments .", "tokens": ["a", "program", "randomly", "clipped", "300", "nucleotide", "fragments", "for", "word", "counting", ".", "as", "a", "result", ",", "one", "random", "300", "nucleotide", "fragment", "from", "each", "training", "sequence", "was", "present", "in", "the", "training", "set", "during", "a", "single", "resampling", "replicate", ";", "independent", "replicates", "contained", "different", ",", "randomly", "chosen", "training", "sequences", "and", "300", "nucleotide", "fragments", "."], "sentence_id": 192, "word_count": 50}, {"text": "values of the test statistic from 40 resampled replicates were pooled for calibration purposes . as with the original protocol , we pooled the resulting test statistic distributions , normalized them as cumulative distributions , and then evaluated them for overlap .", "tokens": ["values", "of", "the", "test", "statistic", "from", "40", "resampled", "replicates", "were", "pooled", "for", "calibration", "purposes", ".", "as", "with", "the", "original", "protocol", ",", "we", "pooled", "the", "resulting", "test", "statistic", "distributions", ",", "normalized", "them", "as", "cumulative", "distributions", ",", "and", "then", "evaluated", "them", "for", "overlap", "."], "sentence_id": 193, "word_count": 42}, {"text": "we call the resulting comparisons ' calibration curves ' , as they are not used directly to make inferences , but rather indirectly , to evaluate the degree of separation in hexamer counts from different taxa", "tokens": ["we", "call", "the", "resulting", "comparisons", "'", "calibration", "curves", "'", ",", "as", "they", "are", "not", "used", "directly", "to", "make", "inferences", ",", "but", "rather", "indirectly", ",", "to", "evaluate", "the", "degree", "of", "separation", "in", "hexamer", "counts", "from", "different", "taxa"], "sentence_id": 194, "word_count": 36}, {"text": ". overlap of calibration curves should be minimal to yield the most statistically powerful results possible .", "tokens": [".", "overlap", "of", "calibration", "curves", "should", "be", "minimal", "to", "yield", "the", "most", "statistically", "powerful", "results", "possible", "."], "sentence_id": 195, "word_count": 17}, {"text": "due to considerable overlap of calibration curves between taxonomically general , inclusive training sets ( that is , all eudicots , all fungi and miscellaneous eukaryotes , and all eubacteria , data not shown ) , we opted to work with specific training sets that included only the most species - specific sequences available , while maintaining approximately equal sample sizes across taxa .", "tokens": ["due", "to", "considerable", "overlap", "of", "calibration", "curves", "between", "taxonomically", "general", ",", "inclusive", "training", "sets", "(", "that", "is", ",", "all", "eudicots", ",", "all", "fungi", "and", "miscellaneous", "eukaryotes", ",", "and", "all", "eubacteria", ",", "data", "not", "shown", ")", ",", "we", "opted", "to", "work", "with", "specific", "training", "sets", "that", "included", "only", "the", "most", "species", "-", "specific", "sequences", "available", ",", "while", "maintaining", "approximately", "equal", "sample", "sizes", "across", "taxa", "."], "sentence_id": 196, "word_count": 64}, {"text": "the most challenging case was that of the arbuscular mycorrhizal fungi , for which very few protein - coding sequences are available . to increase the amount of data in this training set ( b2 ) without biasing sample sizes , we pooled sequences from all species in the zygomycetes with all available chytridiomycete coding sequences , and compared this training set with a set from a single plant genus , medicago ( a2 ) .", "tokens": ["the", "most", "challenging", "case", "was", "that", "of", "the", "arbuscular", "mycorrhizal", "fungi", ",", "for", "which", "very", "few", "protein", "-", "coding", "sequences", "are", "available", ".", "to", "increase", "the", "amount", "of", "data", "in", "this", "training", "set", "(", "b2", ")", "without", "biasing", "sample", "sizes", ",", "we", "pooled", "sequences", "from", "all", "species", "in", "the", "zygomycetes", "with", "all", "available", "chytridiomycete", "coding", "sequences", ",", "and", "compared", "this", "training", "set", "with", "a", "set", "from", "a", "single", "plant", "genus", ",", "medicago", "(", "a2", ")", "."], "sentence_id": 197, "word_count": 76}, {"text": "we chose this option , rather than including an arbitrary subset of sequences from the ascomycetes and basidiomycetes , because zygomycetes and chytridiomycetes have diverged from their common ancestor less recently than the ascomycetes and basidiomycetes , based on 18s ribosomal rna sequence data .", "tokens": ["we", "chose", "this", "option", ",", "rather", "than", "including", "an", "arbitrary", "subset", "of", "sequences", "from", "the", "ascomycetes", "and", "basidiomycetes", ",", "because", "zygomycetes", "and", "chytridiomycetes", "have", "diverged", "from", "their", "common", "ancestor", "less", "recently", "than", "the", "ascomycetes", "and", "basidiomycetes", ",", "based", "on", "18s", "ribosomal", "rna", "sequence", "data", "."], "sentence_id": 198, "word_count": 45}, {"text": "that is , the ascomycetes and basidiomycetes are more highly derived from the common fungal ancestor than zygomycetes and chytridiomycetes , which resemble more closely the ancestral state in modern lineages .", "tokens": ["that", "is", ",", "the", "ascomycetes", "and", "basidiomycetes", "are", "more", "highly", "derived", "from", "the", "common", "fungal", "ancestor", "than", "zygomycetes", "and", "chytridiomycetes", ",", "which", "resemble", "more", "closely", "the", "ancestral", "state", "in", "modern", "lineages", "."], "sentence_id": 199, "word_count": 32}, {"text": "starting with a full set of sequences , we filtered for high - quality sequences by trimming regions having extensive ambiguous bases ( n - rich ) and poly(a ) or poly(t ) regions .", "tokens": ["starting", "with", "a", "full", "set", "of", "sequences", ",", "we", "filtered", "for", "high", "-", "quality", "sequences", "by", "trimming", "regions", "having", "extensive", "ambiguous", "bases", "(", "n", "-", "rich", ")", "and", "poly(a", ")", "or", "poly(t", ")", "regions", "."], "sentence_id": 200, "word_count": 35}, {"text": "thus , we trimmed poly(a ) and poly(t ) sites to minimize the cases in which a test sequence resembles one training set more closely than the other , simply by virtue of having an abundance of the hexamer aaaaaa or tttttt .", "tokens": ["thus", ",", "we", "trimmed", "poly(a", ")", "and", "poly(t", ")", "sites", "to", "minimize", "the", "cases", "in", "which", "a", "test", "sequence", "resembles", "one", "training", "set", "more", "closely", "than", "the", "other", ",", "simply", "by", "virtue", "of", "having", "an", "abundance", "of", "the", "hexamer", "aaaaaa", "or", "tttttt", "."], "sentence_id": 201, "word_count": 43}, {"text": "similarly , test results obtained from short or n - rich sequences can be difficult to interpret .", "tokens": ["similarly", ",", "test", "results", "obtained", "from", "short", "or", "n", "-", "rich", "sequences", "can", "be", "difficult", "to", "interpret", "."], "sentence_id": 202, "word_count": 18}, {"text": "we allowed no more than one n per hexamer and trimmed poly(a ) or poly(t ) tracts longer than 13 nucleotides . to accommodate for possible sequence chimeras ,", "tokens": ["we", "allowed", "no", "more", "than", "one", "n", "per", "hexamer", "and", "trimmed", "poly(a", ")", "or", "poly(t", ")", "tracts", "longer", "than", "13", "nucleotides", ".", "to", "accommodate", "for", "possible", "sequence", "chimeras", ","], "sentence_id": 203, "word_count": 29}, {"text": "those sequences found to contain an internal poly(a ) or poly(t ) segment longer than 13 nucleotides were partitioned into two fragments , and the longer of the two fragments was used in analysis , provided its length was at least 300 nucleotides . after trimming , we screened all remaining sequences of 300 nt or longer for similarity to escherichia coli using blastn .", "tokens": ["those", "sequences", "found", "to", "contain", "an", "internal", "poly(a", ")", "or", "poly(t", ")", "segment", "longer", "than", "13", "nucleotides", "were", "partitioned", "into", "two", "fragments", ",", "and", "the", "longer", "of", "the", "two", "fragments", "was", "used", "in", "analysis", ",", "provided", "its", "length", "was", "at", "least", "300", "nucleotides", ".", "after", "trimming", ",", "we", "screened", "all", "remaining", "sequences", "of", "300", "nt", "or", "longer", "for", "similarity", "to", "escherichia", "coli", "using", "blastn", "."], "sentence_id": 204, "word_count": 65}, {"text": "all blast searches used default parameters and low - complexity filtering with the programs dust or seg .", "tokens": ["all", "blast", "searches", "used", "default", "parameters", "and", "low", "-", "complexity", "filtering", "with", "the", "programs", "dust", "or", "seg", "."], "sentence_id": 205, "word_count": 18}, {"text": "the decision to exclude non - coding rna sequences from training sets was informed by the appearance of bimodal distributions of hexamer frequencies and a large degree of overlap between calibration curves ( data not shown ) , likely a result of divergent evolutionary rates between protein - coding and non - coding sequences .", "tokens": ["the", "decision", "to", "exclude", "non", "-", "coding", "rna", "sequences", "from", "training", "sets", "was", "informed", "by", "the", "appearance", "of", "bimodal", "distributions", "of", "hexamer", "frequencies", "and", "a", "large", "degree", "of", "overlap", "between", "calibration", "curves", "(", "data", "not", "shown", ")", ",", "likely", "a", "result", "of", "divergent", "evolutionary", "rates", "between", "protein", "-", "coding", "and", "non", "-", "coding", "sequences", "."], "sentence_id": 206, "word_count": 55}, {"text": "chloroplast and mitochondrial sequences were eliminated to avoid complications due to variation in codon usage between nuclear and organellar genomes .", "tokens": ["chloroplast", "and", "mitochondrial", "sequences", "were", "eliminated", "to", "avoid", "complications", "due", "to", "variation", "in", "codon", "usage", "between", "nuclear", "and", "organellar", "genomes", "."], "sentence_id": 207, "word_count": 21}, {"text": "table 2 summarizes counts of sequences and nucleotides in training sets before and after trimming and screening .", "tokens": ["table", "2", "summarizes", "counts", "of", "sequences", "and", "nucleotides", "in", "training", "sets", "before", "and", "after", "trimming", "and", "screening", "."], "sentence_id": 208, "word_count": 18}, {"text": "to test the validity of word counting as a solution to the problem , we identified a set of 50 gene sequences from plants ( m. truncatula and g. max ) , oomycetes ( phytophthora ) , zygomycetes ( glomus versiforme ) , and bacteria ( sinorhizobium meliloti and agrobacterium tumefaciens ) , for which the function and origin have been characterized experimentally .", "tokens": ["to", "test", "the", "validity", "of", "word", "counting", "as", "a", "solution", "to", "the", "problem", ",", "we", "identified", "a", "set", "of", "50", "gene", "sequences", "from", "plants", "(", "m.", "truncatula", "and", "g.", "max", ")", ",", "oomycetes", "(", "phytophthora", ")", ",", "zygomycetes", "(", "glomus", "versiforme", ")", ",", "and", "bacteria", "(", "sinorhizobium", "meliloti", "and", "agrobacterium", "tumefaciens", ")", ",", "for", "which", "the", "function", "and", "origin", "have", "been", "characterized", "experimentally", "."], "sentence_id": 209, "word_count": 64}, {"text": "we chose genes known to play a role in plant - microbe interactions , as well as genes that are found across taxa .", "tokens": ["we", "chose", "genes", "known", "to", "play", "a", "role", "in", "plant", "-", "microbe", "interactions", ",", "as", "well", "as", "genes", "that", "are", "found", "across", "taxa", "."], "sentence_id": 210, "word_count": 24}, {"text": "we withheld these sequences , and partial transcripts of the same genes , from training sets prior to comparative lexical analysis , and calculated hexamer dissimilarities for each of the three training sets as described below .", "tokens": ["we", "withheld", "these", "sequences", ",", "and", "partial", "transcripts", "of", "the", "same", "genes", ",", "from", "training", "sets", "prior", "to", "comparative", "lexical", "analysis", ",", "and", "calculated", "hexamer", "dissimilarities", "for", "each", "of", "the", "three", "training", "sets", "as", "described", "below", "."], "sentence_id": 211, "word_count": 37}, {"text": "to diagnose the species of origin for sequences expressed in symbiotic cultures , we collected sequences generated by distinct est sequencing projects from the genbank database .", "tokens": ["to", "diagnose", "the", "species", "of", "origin", "for", "sequences", "expressed", "in", "symbiotic", "cultures", ",", "we", "collected", "sequences", "generated", "by", "distinct", "est", "sequencing", "projects", "from", "the", "genbank", "database", "."], "sentence_id": 212, "word_count": 27}, {"text": "sequences from pathogenic interactions originated from cultures of a species from the genus phytophthora with its plant host , such as p. sojae and soybean ( g. max ) isolated from inoculated hypocotyls two days after infection   and p. medicaginis and m. truncatula isolated from infected roots 10 days after infection ( c. vance , unpublished data ) .", "tokens": ["sequences", "from", "pathogenic", "interactions", "originated", "from", "cultures", "of", "a", "species", "from", "the", "genus", "phytophthora", "with", "its", "plant", "host", ",", "such", "as", "p.", "sojae", "and", "soybean", "(", "g.", "max", ")", "isolated", "from", "inoculated", "hypocotyls", "two", "days", "after", "infection", "and", "p.", "medicaginis", "and", "m.", "truncatula", "isolated", "from", "infected", "roots", "10", "days", "after", "infection", "(", "c.", "vance", ",", "unpublished", "data", ")", "."], "sentence_id": 213, "word_count": 59}, {"text": "sequences expressed during mutualistic interactions were obtained from cultures with m. truncatula and mycorrhizal ( glomus versiforme ; m.j .", "tokens": ["sequences", "expressed", "during", "mutualistic", "interactions", "were", "obtained", "from", "cultures", "with", "m.", "truncatula", "and", "mycorrhizal", "(", "glomus", "versiforme", ";", "m.j", "."], "sentence_id": 214, "word_count": 20}, {"text": "harrison , unpublished data ) or rhizobacterial ( s. meliloti ; k. vandenbosch , unpublished data ) endosymbionts several days after inoculation", "tokens": ["harrison", ",", "unpublished", "data", ")", "or", "rhizobacterial", "(", "s.", "meliloti", ";", "k.", "vandenbosch", ",", "unpublished", "data", ")", "endosymbionts", "several", "days", "after", "inoculation"], "sentence_id": 215, "word_count": 22}, {"text": ". sequences expressed in pure , axenic cultures from p. sojae mycelia and zoospores   and from sterile , uninoculated m. truncatula roots   provided a basis for comparison in which no foreign transcripts were expected . to maximize the reliability of diagnostic comparisons , we screened test sequences for high quality as for training sequences , and for low similarity to e. coli , chloroplast and mitochondrial genes , and non - coding rna transcripts ( ribosomal and transfer rnas ) .", "tokens": [".", "sequences", "expressed", "in", "pure", ",", "axenic", "cultures", "from", "p.", "sojae", "mycelia", "and", "zoospores", "and", "from", "sterile", ",", "uninoculated", "m.", "truncatula", "roots", "provided", "a", "basis", "for", "comparison", "in", "which", "no", "foreign", "transcripts", "were", "expected", ".", "to", "maximize", "the", "reliability", "of", "diagnostic", "comparisons", ",", "we", "screened", "test", "sequences", "for", "high", "quality", "as", "for", "training", "sequences", ",", "and", "for", "low", "similarity", "to", "e.", "coli", ",", "chloroplast", "and", "mitochondrial", "genes", ",", "and", "non", "-", "coding", "rna", "transcripts", "(", "ribosomal", "and", "transfer", "rnas", ")", "."], "sentence_id": 216, "word_count": 81}, {"text": "independent blastn comparisons identified sequences having very high similarity ( e < 10 ) to vector sequences or moderately high similarity ( e < 10 ) to non - nuclear or non - coding sequences obtained from genbank .", "tokens": ["independent", "blastn", "comparisons", "identified", "sequences", "having", "very", "high", "similarity", "(", "e", "<", "10", ")", "to", "vector", "sequences", "or", "moderately", "high", "similarity", "(", "e", "<", "10", ")", "to", "non", "-", "nuclear", "or", "non", "-", "coding", "sequences", "obtained", "from", "genbank", "."], "sentence_id": 217, "word_count": 39}, {"text": "we wrote a perl program ( countgc.pl ) that calculates the gc base content of a sequence as the portion of guanine and cytosine residues among all unambiguous ( non - n ) nucleotides in a sequence . the hist method in r ,", "tokens": ["we", "wrote", "a", "perl", "program", "(", "countgc.pl", ")", "that", "calculates", "the", "gc", "base", "content", "of", "a", "sequence", "as", "the", "portion", "of", "guanine", "and", "cytosine", "residues", "among", "all", "unambiguous", "(", "non", "-", "n", ")", "nucleotides", "in", "a", "sequence", ".", "the", "hist", "method", "in", "r", ","], "sentence_id": 218, "word_count": 44}, {"text": "version 1.1.1   aggregated continuous percentages into discrete histogram bins , using bin sizes of 2% difference in gc , with inclusive lower bin boundaries and exclusive upper bounds ; the lm method tested for linear correlation of the dissimilarity test statistic t with gc .", "tokens": ["version", "1.1.1", "aggregated", "continuous", "percentages", "into", "discrete", "histogram", "bins", ",", "using", "bin", "sizes", "of", "2%", "difference", "in", "gc", ",", "with", "inclusive", "lower", "bin", "boundaries", "and", "exclusive", "upper", "bounds", ";", "the", "lm", "method", "tested", "for", "linear", "correlation", "of", "the", "dissimilarity", "test", "statistic", "t", "with", "gc", "."], "sentence_id": 219, "word_count": 45}, {"text": "white et al .   used a likelihood - ratio test to determine whether word frequencies from a particular sequence more closely resemble the frequency distribution of control data sets from the taxon being sequenced or a distantly related outgroup .", "tokens": ["white", "et", "al", ".", "used", "a", "likelihood", "-", "ratio", "test", "to", "determine", "whether", "word", "frequencies", "from", "a", "particular", "sequence", "more", "closely", "resemble", "the", "frequency", "distribution", "of", "control", "data", "sets", "from", "the", "taxon", "being", "sequenced", "or", "a", "distantly", "related", "outgroup", "."], "sentence_id": 220, "word_count": 40}, {"text": "they computed a test statistic t(a , b , x ) for each sequence x as the difference of log - likelihood ratio dissimilarity measures , d(a , x ) = -2log(a , x ) , for two data sets , a control set a and an outgroup b , such that t(a , b , x ) = d(a , x ) - d(b , x ) .", "tokens": ["they", "computed", "a", "test", "statistic", "t(a", ",", "b", ",", "x", ")", "for", "each", "sequence", "x", "as", "the", "difference", "of", "log", "-", "likelihood", "ratio", "dissimilarity", "measures", ",", "d(a", ",", "x", ")", "=", "-2log(a", ",", "x", ")", ",", "for", "two", "data", "sets", ",", "a", "control", "set", "a", "and", "an", "outgroup", "b", ",", "such", "that", "t(a", ",", "b", ",", "x", ")", "=", "d(a", ",", "x", ")", "-", "d(b", ",", "x", ")", "."], "sentence_id": 221, "word_count": 69}, {"text": "a negative value for t indicates that the sequence more closely resembles words from a ; conversely , a positive value indicates a likely contaminant related to b. ( dissimilarity is conceptually related to distance . however , dissimilarity does not measure distance because it does not possess the mathematical properties of a distance metric . ) unlike the calculation of calibration curves , in which 300-nucleotide subsequences are randomly resampled , hexamer dissimilarity is measured over the whole length of a test sequence when inferring a transcript 's origin .", "tokens": ["a", "negative", "value", "for", "t", "indicates", "that", "the", "sequence", "more", "closely", "resembles", "words", "from", "a", ";", "conversely", ",", "a", "positive", "value", "indicates", "a", "likely", "contaminant", "related", "to", "b.", "(", "dissimilarity", "is", "conceptually", "related", "to", "distance", ".", "however", ",", "dissimilarity", "does", "not", "measure", "distance", "because", "it", "does", "not", "possess", "the", "mathematical", "properties", "of", "a", "distance", "metric", ".", ")", "unlike", "the", "calculation", "of", "calibration", "curves", ",", "in", "which", "300-nucleotide", "subsequences", "are", "randomly", "resampled", ",", "hexamer", "dissimilarity", "is", "measured", "over", "the", "whole", "length", "of", "a", "test", "sequence", "when", "inferring", "a", "transcript", "'s", "origin", "."], "sentence_id": 222, "word_count": 91}, {"text": "originally , the investigators used the null hypothesis that no difference exists for dissimilarity measures between the two data sets , or that t(a , b , x ) = 0 .", "tokens": ["originally", ",", "the", "investigators", "used", "the", "null", "hypothesis", "that", "no", "difference", "exists", "for", "dissimilarity", "measures", "between", "the", "two", "data", "sets", ",", "or", "that", "t(a", ",", "b", ",", "x", ")", "=", "0", "."], "sentence_id": 223, "word_count": 32}, {"text": "white et al .   tested two alternative hypotheses : that t < 0 , being more like a , or t > 0 , like b. lexical analysis using pentamers or heptamers yields similar error rates and very highly correlated values for the test result ( not shown ) . because white et al .  ", "tokens": ["white", "et", "al", ".", "tested", "two", "alternative", "hypotheses", ":", "that", "t", "<", "0", ",", "being", "more", "like", "a", ",", "or", "t", ">", "0", ",", "like", "b.", "lexical", "analysis", "using", "pentamers", "or", "heptamers", "yields", "similar", "error", "rates", "and", "very", "highly", "correlated", "values", "for", "the", "test", "result", "(", "not", "shown", ")", ".", "because", "white", "et", "al", "."], "sentence_id": 224, "word_count": 55}, {"text": "reported the best results were obtained using hexamers , and because a word size of six nucleotides corresponds to the size of a dicodon , we chose to analyze hexamer frequencies . to use longer words requires more training data , because the number of possible words increases exponentially with increasing word size .", "tokens": ["reported", "the", "best", "results", "were", "obtained", "using", "hexamers", ",", "and", "because", "a", "word", "size", "of", "six", "nucleotides", "corresponds", "to", "the", "size", "of", "a", "dicodon", ",", "we", "chose", "to", "analyze", "hexamer", "frequencies", ".", "to", "use", "longer", "words", "requires", "more", "training", "data", ",", "because", "the", "number", "of", "possible", "words", "increases", "exponentially", "with", "increasing", "word", "size", "."], "sentence_id": 225, "word_count": 54}, {"text": "use of shorter words may be adequate for some applications and will be investigated in future work . though we used white 's word - counting methods , we did make slight modifications .", "tokens": ["use", "of", "shorter", "words", "may", "be", "adequate", "for", "some", "applications", "and", "will", "be", "investigated", "in", "future", "work", ".", "though", "we", "used", "white", "'s", "word", "-", "counting", "methods", ",", "we", "did", "make", "slight", "modifications", "."], "sentence_id": 226, "word_count": 34}, {"text": "we simplified one program ( called hybridize ) to compute individual dissimilarity values , rather than paired differences ; a patch that details how to modify the c program is available ( see hyb2dis.txt in additional data files ) .", "tokens": ["we", "simplified", "one", "program", "(", "called", "hybridize", ")", "to", "compute", "individual", "dissimilarity", "values", ",", "rather", "than", "paired", "differences", ";", "a", "patch", "that", "details", "how", "to", "modify", "the", "c", "program", "is", "available", "(", "see", "hyb2dis.txt", "in", "additional", "data", "files", ")", "."], "sentence_id": 227, "word_count": 40}, {"text": "more importantly , we amended the null hypothesis and interpreted calibration curves to test for statistically significant dissimilarity differences . though the likelihood - ratio test statistic indicates the magnitude of similarity to a or b , we do not know what values for t are significant with known confidence .", "tokens": ["more", "importantly", ",", "we", "amended", "the", "null", "hypothesis", "and", "interpreted", "calibration", "curves", "to", "test", "for", "statistically", "significant", "dissimilarity", "differences", ".", "though", "the", "likelihood", "-", "ratio", "test", "statistic", "indicates", "the", "magnitude", "of", "similarity", "to", "a", "or", "b", ",", "we", "do", "not", "know", "what", "values", "for", "t", "are", "significant", "with", "known", "confidence", "."], "sentence_id": 228, "word_count": 51}, {"text": "when testing hypotheses , one can make two types of error : type i , or false positives , and type ii , false negatives .", "tokens": ["when", "testing", "hypotheses", ",", "one", "can", "make", "two", "types", "of", "error", ":", "type", "i", ",", "or", "false", "positives", ",", "and", "type", "ii", ",", "false", "negatives", "."], "sentence_id": 229, "word_count": 26}, {"text": "the false - positive rate is denoted  and false - negative rate . we determine  and  from overlap in the calibration curves . inferring error rates from calibration curves", "tokens": ["the", "false", "-", "positive", "rate", "is", "denoted", "and", "false", "-", "negative", "rate", ".", "we", "determine", "and", "from", "overlap", "in", "the", "calibration", "curves", ".", "inferring", "error", "rates", "from", "calibration", "curves"], "sentence_id": 230, "word_count": 29}, {"text": "is justified because we know the correct answer and determine the error rate via resampling , as with bootstrap methods to infer error rates or confidence intervals .", "tokens": ["is", "justified", "because", "we", "know", "the", "correct", "answer", "and", "determine", "the", "error", "rate", "via", "resampling", ",", "as", "with", "bootstrap", "methods", "to", "infer", "error", "rates", "or", "confidence", "intervals", "."], "sentence_id": 231, "word_count": 28}, {"text": "we are interested in knowing from which of two organisms a sequence originated , and are reasonably confident that it came from either one or the other .", "tokens": ["we", "are", "interested", "in", "knowing", "from", "which", "of", "two", "organisms", "a", "sequence", "originated", ",", "and", "are", "reasonably", "confident", "that", "it", "came", "from", "either", "one", "or", "the", "other", "."], "sentence_id": 232, "word_count": 28}, {"text": "thus , we assume it came from one and test whether we have evidence to refute this assumption .", "tokens": ["thus", ",", "we", "assume", "it", "came", "from", "one", "and", "test", "whether", "we", "have", "evidence", "to", "refute", "this", "assumption", "."], "sentence_id": 233, "word_count": 19}, {"text": "the null hypothesis here is that sequence x is from a. alternatively , it might be from b. evaluating the calibration curve overlap at t = 0 quantifies the associated error rates .", "tokens": ["the", "null", "hypothesis", "here", "is", "that", "sequence", "x", "is", "from", "a.", "alternatively", ",", "it", "might", "be", "from", "b.", "evaluating", "the", "calibration", "curve", "overlap", "at", "t", "=", "0", "quantifies", "the", "associated", "error", "rates", "."], "sentence_id": 234, "word_count": 33}, {"text": "the cumulative distribution function ( cdf ) of taxon b specifies  where cdfb intersects 0 ; the cdf from a specifies  as 1-cdfa(0 )", "tokens": ["the", "cumulative", "distribution", "function", "(", "cdf", ")", "of", "taxon", "b", "specifies", "where", "cdfb", "intersects", "0", ";", "the", "cdf", "from", "a", "specifies", "as", "1-cdfa(0", ")"], "sentence_id": 235, "word_count": 24}, {"text": ". we can thus resolve the problem with known confidence p : p ( t > 0 ) = . all other computations were performed as described previously .", "tokens": [".", "we", "can", "thus", "resolve", "the", "problem", "with", "known", "confidence", "p", ":", "p", "(", "t", ">", "0", ")", "=", ".", "all", "other", "computations", "were", "performed", "as", "described", "previously", "."], "sentence_id": 236, "word_count": 29}, {"text": "software used for lexical analysis was obtained via anonymous ftp from the tigr software ftp site .", "tokens": ["software", "used", "for", "lexical", "analysis", "was", "obtained", "via", "anonymous", "ftp", "from", "the", "tigr", "software", "ftp", "site", "."], "sentence_id": 237, "word_count": 17}, {"text": "the following files are available for download : countgc.pl : perl script used to compute gc content of sequences analyzed .", "tokens": ["the", "following", "files", "are", "available", "for", "download", ":", "countgc.pl", ":", "perl", "script", "used", "to", "compute", "gc", "content", "of", "sequences", "analyzed", "."], "sentence_id": 238, "word_count": 21}, {"text": "hyb2dis.txt : patch file that converts white 's hybridize program to compute individual dissimilarity values .", "tokens": ["hyb2dis.txt", ":", "patch", "file", "that", "converts", "white", "'s", "hybridize", "program", "to", "compute", "individual", "dissimilarity", "values", "."], "sentence_id": 239, "word_count": 16}, {"text": "training sets ( glycinemedicago.txt,rhizobia.txt , stramenopiles.txt , zygochytrid.txt ) : fasta - formatted text files that contain the sequences used for calibration and comparison .", "tokens": ["training", "sets", "(", "glycinemedicago.txt,rhizobia.txt", ",", "stramenopiles.txt", ",", "zygochytrid.txt", ")", ":", "fasta", "-", "formatted", "text", "files", "that", "contain", "the", "sequences", "used", "for", "calibration", "and", "comparison", "."], "sentence_id": 240, "word_count": 25}, {"text": "test sets ( psojaeha.txt , psojaemy.txt , psojaezo.txt , mtrhe.txt , dsir.txt , mham.txt , kv0.txt , kv2.txt , kv3.txt ) : fasta - formatted text files containing transcripts analyzed , edited for quality .", "tokens": ["test", "sets", "(", "psojaeha.txt", ",", "psojaemy.txt", ",", "psojaezo.txt", ",", "mtrhe.txt", ",", "dsir.txt", ",", "mham.txt", ",", "kv0.txt", ",", "kv2.txt", ",", "kv3.txt", ")", ":", "fasta", "-", "formatted", "text", "files", "containing", "transcripts", "analyzed", ",", "edited", "for", "quality", "."], "sentence_id": 241, "word_count": 35}, {"text": "test results ( psojaeha.dat , psojaemy.dat , psojaezo.dat , mtrhe-a1b1.dat , mtrhe-a2b2.dat , dsir.dat , mham.dat , kv0.dat , kv2.dat , kv3.dat ) : text files that contain transcript analysis results , sorted from least to most plant - like .", "tokens": ["test", "results", "(", "psojaeha.dat", ",", "psojaemy.dat", ",", "psojaezo.dat", ",", "mtrhe-a1b1.dat", ",", "mtrhe-a2b2.dat", ",", "dsir.dat", ",", "mham.dat", ",", "kv0.dat", ",", "kv2.dat", ",", "kv3.dat", ")", ":", "text", "files", "that", "contain", "transcript", "analysis", "results", ",", "sorted", "from", "least", "to", "most", "plant", "-", "like", "."], "sentence_id": 242, "word_count": 41}, {"text": "fasta - formatted text files containing transcripts analyzed , edited for quality . text files that contain transcript analysis results , sorted from least to most plant - like .", "tokens": ["fasta", "-", "formatted", "text", "files", "containing", "transcripts", "analyzed", ",", "edited", "for", "quality", ".", "text", "files", "that", "contain", "transcript", "analysis", "results", ",", "sorted", "from", "least", "to", "most", "plant", "-", "like", "."], "sentence_id": 243, "word_count": 30}, {"text": "we thank callum bell , mark gijzen , maria harrison , tom kepler , deb samac , and bruno sobral for valued discussions and feedback . comments from b. m. tyler and an anonymous reviewer on an earlier version of this work greatly enhanced its presentation .", "tokens": ["we", "thank", "callum", "bell", ",", "mark", "gijzen", ",", "maria", "harrison", ",", "tom", "kepler", ",", "deb", "samac", ",", "and", "bruno", "sobral", "for", "valued", "discussions", "and", "feedback", ".", "comments", "from", "b.", "m.", "tyler", "and", "an", "anonymous", "reviewer", "on", "an", "earlier", "version", "of", "this", "work", "greatly", "enhanced", "its", "presentation", "."], "sentence_id": 244, "word_count": 47}, {"text": "distribution of gc content in pure and mixed - culture libraries . ( a ) probability densities for histogram bin sizes of 0.02 ( 2% ) in base content .", "tokens": ["distribution", "of", "gc", "content", "in", "pure", "and", "mixed", "-", "culture", "libraries", ".", "(", "a", ")", "probability", "densities", "for", "histogram", "bin", "sizes", "of", "0.02", "(", "2%", ")", "in", "base", "content", "."], "sentence_id": 245, "word_count": 30}, {"text": "( a ) calculation of statistical parameters from cdfs a and b. overlap in the upper tail of cdfa with cdfb and the lower tail of cdfb with cdfa are likely regions for error .", "tokens": ["(", "a", ")", "calculation", "of", "statistical", "parameters", "from", "cdfs", "a", "and", "b.", "overlap", "in", "the", "upper", "tail", "of", "cdfa", "with", "cdfb", "and", "the", "lower", "tail", "of", "cdfb", "with", "cdfa", "are", "likely", "regions", "for", "error", "."], "sentence_id": 246, "word_count": 35}, {"text": "we find the false - positive rate  where 1 - cdfa intersects 0 [ cdfa(0)= 1 -  ] , and the false - negative rate  where cdfb crosses 0 . also shown", "tokens": ["we", "find", "the", "false", "-", "positive", "rate", "where", "1", "-", "cdfa", "intersects", "0", "[", "cdfa(0)=", "1", "-", "]", ",", "and", "the", "false", "-", "negative", "rate", "where", "cdfb", "crosses", "0", ".", "also", "shown"], "sentence_id": 247, "word_count": 32}, {"text": "are the medians (  ) for each distribution , where cdf( ) = 0.5 .", "tokens": ["are", "the", "medians", "(", ")", "for", "each", "distribution", ",", "where", "cdf(", ")", "=", "0.5", "."], "sentence_id": 248, "word_count": 15}, {"text": ", solid black line ) and stramenopile plus p. infestans est ( b1 , dashed black line ) training sequences .", "tokens": [",", "solid", "black", "line", ")", "and", "stramenopile", "plus", "p.", "infestans", "est", "(", "b1", ",", "dashed", "black", "line", ")", "training", "sequences", "."], "sentence_id": 249, "word_count": 21}, {"text": "superimposed distributions of test results show dissimilarity differences for infected g. max ( green ) and axenic p. sojae mycelial and zoospore sequences ( blue and cyan , respectively ) .", "tokens": ["superimposed", "distributions", "of", "test", "results", "show", "dissimilarity", "differences", "for", "infected", "g.", "max", "(", "green", ")", "and", "axenic", "p.", "sojae", "mycelial", "and", "zoospore", "sequences", "(", "blue", "and", "cyan", ",", "respectively", ")", "."], "sentence_id": 250, "word_count": 31}, {"text": "each point corresponds to an expressed tag from either ( a ) infected g. max or ( b ) axenic p. sojae mycelial or ( c ) zoospore sequences , compared with plant ( a1 ) and stramenopile plus p. infestans est training sequences ( b1 ) .", "tokens": ["each", "point", "corresponds", "to", "an", "expressed", "tag", "from", "either", "(", "a", ")", "infected", "g.", "max", "or", "(", "b", ")", "axenic", "p.", "sojae", "mycelial", "or", "(", "c", ")", "zoospore", "sequences", ",", "compared", "with", "plant", "(", "a1", ")", "and", "stramenopile", "plus", "p.", "infestans", "est", "training", "sequences", "(", "b1", ")", "."], "sentence_id": 251, "word_count": 48}, {"text": "the identity function indicates equal dissimilarity to both training sets , t = d(a ) - d(b)= 0 .", "tokens": ["the", "identity", "function", "indicates", "equal", "dissimilarity", "to", "both", "training", "sets", ",", "t", "=", "d(a", ")", "-", "d(b)=", "0", "."], "sentence_id": 252, "word_count": 19}, {"text": "calibration curves compare plant training sets ( a1 and a2 , solid black lines ) with one of three microbial symbiont training sets ( broken black lines ) : ( a ) stramenopile and p. infestans est sequences ( b1 ) ; ( b ) pooled zygomycete and chytridiomycete coding sequences ( b2 ) ; and ( c ) sequences from the genera rhizobium , sinorhizobium and bradyrhizobium ( b3 ) .", "tokens": ["calibration", "curves", "compare", "plant", "training", "sets", "(", "a1", "and", "a2", ",", "solid", "black", "lines", ")", "with", "one", "of", "three", "microbial", "symbiont", "training", "sets", "(", "broken", "black", "lines", ")", ":", "(", "a", ")", "stramenopile", "and", "p.", "infestans", "est", "sequences", "(", "b1", ")", ";", "(", "b", ")", "pooled", "zygomycete", "and", "chytridiomycete", "coding", "sequences", "(", "b2", ")", ";", "and", "(", "c", ")", "sequences", "from", "the", "genera", "rhizobium", ",", "sinorhizobium", "and", "bradyrhizobium", "(", "b3", ")", "."], "sentence_id": 253, "word_count": 72}, {"text": "cumulative distributions of test results from m. truncatula axenic and microbial symbiont mixed cultures appear in each panel ( colored lines ) .", "tokens": ["cumulative", "distributions", "of", "test", "results", "from", "m.", "truncatula", "axenic", "and", "microbial", "symbiont", "mixed", "cultures", "appear", "in", "each", "panel", "(", "colored", "lines", ")", "."], "sentence_id": 254, "word_count": 23}, {"text": "each point indicates the dissimilarity of a test sequence compared with a plant training set ( a1 or a2 ) and one of three microbial symbiont training sets : ( a ) stramenopile and p. infestans est sequences ( b1 ) ; ( b ) pooled zygomycete and chytridiomycete coding sequences ( b2 ) ; and ( c ) sequences from the genera rhizobium , sinorhizobium and bradyrhizobium ( b3 ) . sequences from m. truncatula axenic ( green ) and microbial symbiont mixed culture libraries are represented in each panel .", "tokens": ["each", "point", "indicates", "the", "dissimilarity", "of", "a", "test", "sequence", "compared", "with", "a", "plant", "training", "set", "(", "a1", "or", "a2", ")", "and", "one", "of", "three", "microbial", "symbiont", "training", "sets", ":", "(", "a", ")", "stramenopile", "and", "p.", "infestans", "est", "sequences", "(", "b1", ")", ";", "(", "b", ")", "pooled", "zygomycete", "and", "chytridiomycete", "coding", "sequences", "(", "b2", ")", ";", "and", "(", "c", ")", "sequences", "from", "the", "genera", "rhizobium", ",", "sinorhizobium", "and", "bradyrhizobium", "(", "b3", ")", ".", "sequences", "from", "m.", "truncatula", "axenic", "(", "green", ")", "and", "microbial", "symbiont", "mixed", "culture", "libraries", "are", "represented", "in", "each", "panel", "."], "sentence_id": 255, "word_count": 92}, {"text": "number of sequences ( n ) and nucleotides ( nt ) , as raw , trimmed ( removed n - rich regions , poly(a ) and poly(t ) sites ) , and screened sequences ( removed ribosomal , chloroplast , and mitochondrial dna and remaining sequences shorter than 300 nucleotides ) .", "tokens": ["number", "of", "sequences", "(", "n", ")", "and", "nucleotides", "(", "nt", ")", ",", "as", "raw", ",", "trimmed", "(", "removed", "n", "-", "rich", "regions", ",", "poly(a", ")", "and", "poly(t", ")", "sites", ")", ",", "and", "screened", "sequences", "(", "removed", "ribosomal", ",", "chloroplast", ",", "and", "mitochondrial", "dna", "and", "remaining", "sequences", "shorter", "than", "300", "nucleotides", ")", "."], "sentence_id": 256, "word_count": 52}, {"text": "number of est sequences ( n ) and nucleotides ( nt ) as raw , trimmed ( limited lengths of n - rich regions , poly(a ) and poly(t ) sites ) , and screened ( removed ribosomal , chloroplast , and mitochondrial dna , and remaining sequences shorter than 300 nt ) sequences .", "tokens": ["number", "of", "est", "sequences", "(", "n", ")", "and", "nucleotides", "(", "nt", ")", "as", "raw", ",", "trimmed", "(", "limited", "lengths", "of", "n", "-", "rich", "regions", ",", "poly(a", ")", "and", "poly(t", ")", "sites", ")", ",", "and", "screened", "(", "removed", "ribosomal", ",", "chloroplast", ",", "and", "mitochondrial", "dna", ",", "and", "remaining", "sequences", "shorter", "than", "300", "nt", ")", "sequences", "."], "sentence_id": 257, "word_count": 55}], "section_names": ["background", "results", "discussion", "methods and materials", "training sequences", "calibration", "data quality", "validation", "test sequences", "base content", "comparative lexical analysis", "additional data files", "supplementary material", "acknowledgements", "figures and tables"], "section_lengths": [26, 38, 34, 55, 29, 17, 9, 3, 6, 2, 18, 5, 1, 1, 13]}